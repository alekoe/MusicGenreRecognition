{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc547b1-84d4-4ba6-a8a1-8877423fe056",
   "metadata": {},
   "source": [
    "\n",
    "# Train GRU Model from WavLM features and discrete labels\n",
    "\n",
    "### For GTzan dataset - 3CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760109a1-c818-49cf-abd3-377b65994a33",
   "metadata": {},
   "source": [
    "##### https://github.com/microsoft/unilm/tree/master/wavlm\n",
    "##### https://github.com/audeering/w2v2-how-to/blob/main/notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8263d9b9-de2b-418e-b1a5-da5323499a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c814ae24",
   "metadata": {},
   "source": [
    "### Process Feature Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82648fce-e07c-4188-a7b0-d1bd585c1e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/etsmtl/akoerich/DEV/Music\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191da55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blues.00000.wavlmlargefeat',\n",
       " 'blues.00001.wavlmlargefeat',\n",
       " 'blues.00002.wavlmlargefeat',\n",
       " 'blues.00003.wavlmlargefeat',\n",
       " 'blues.00004.wavlmlargefeat',\n",
       " 'blues.00005.wavlmlargefeat',\n",
       " 'blues.00006.wavlmlargefeat',\n",
       " 'blues.00007.wavlmlargefeat',\n",
       " 'blues.00008.wavlmlargefeat',\n",
       " 'blues.00009.wavlmlargefeat',\n",
       " 'blues.00010.wavlmlargefeat',\n",
       " 'blues.00011.wavlmlargefeat',\n",
       " 'blues.00012.wavlmlargefeat',\n",
       " 'blues.00013.wavlmlargefeat',\n",
       " 'blues.00014.wavlmlargefeat',\n",
       " 'blues.00015.wavlmlargefeat',\n",
       " 'blues.00016.wavlmlargefeat',\n",
       " 'blues.00017.wavlmlargefeat',\n",
       " 'blues.00018.wavlmlargefeat',\n",
       " 'blues.00019.wavlmlargefeat',\n",
       " 'blues.00020.wavlmlargefeat',\n",
       " 'blues.00021.wavlmlargefeat',\n",
       " 'blues.00022.wavlmlargefeat',\n",
       " 'blues.00023.wavlmlargefeat',\n",
       " 'blues.00024.wavlmlargefeat',\n",
       " 'blues.00025.wavlmlargefeat',\n",
       " 'blues.00026.wavlmlargefeat',\n",
       " 'blues.00027.wavlmlargefeat',\n",
       " 'blues.00028.wavlmlargefeat',\n",
       " 'blues.00029.wavlmlargefeat',\n",
       " 'blues.00030.wavlmlargefeat',\n",
       " 'blues.00031.wavlmlargefeat',\n",
       " 'blues.00032.wavlmlargefeat',\n",
       " 'blues.00033.wavlmlargefeat',\n",
       " 'blues.00034.wavlmlargefeat',\n",
       " 'blues.00035.wavlmlargefeat',\n",
       " 'blues.00036.wavlmlargefeat',\n",
       " 'blues.00037.wavlmlargefeat',\n",
       " 'blues.00038.wavlmlargefeat',\n",
       " 'blues.00039.wavlmlargefeat',\n",
       " 'blues.00040.wavlmlargefeat',\n",
       " 'blues.00041.wavlmlargefeat',\n",
       " 'blues.00042.wavlmlargefeat',\n",
       " 'blues.00043.wavlmlargefeat',\n",
       " 'blues.00044.wavlmlargefeat',\n",
       " 'blues.00045.wavlmlargefeat',\n",
       " 'blues.00046.wavlmlargefeat',\n",
       " 'blues.00047.wavlmlargefeat',\n",
       " 'blues.00048.wavlmlargefeat',\n",
       " 'blues.00049.wavlmlargefeat',\n",
       " 'blues.00050.wavlmlargefeat',\n",
       " 'blues.00051.wavlmlargefeat',\n",
       " 'blues.00052.wavlmlargefeat',\n",
       " 'blues.00053.wavlmlargefeat',\n",
       " 'blues.00054.wavlmlargefeat',\n",
       " 'blues.00055.wavlmlargefeat',\n",
       " 'blues.00056.wavlmlargefeat',\n",
       " 'blues.00057.wavlmlargefeat',\n",
       " 'blues.00058.wavlmlargefeat',\n",
       " 'blues.00059.wavlmlargefeat',\n",
       " 'blues.00060.wavlmlargefeat',\n",
       " 'blues.00061.wavlmlargefeat',\n",
       " 'blues.00062.wavlmlargefeat',\n",
       " 'blues.00063.wavlmlargefeat',\n",
       " 'blues.00064.wavlmlargefeat',\n",
       " 'blues.00065.wavlmlargefeat',\n",
       " 'blues.00066.wavlmlargefeat',\n",
       " 'blues.00067.wavlmlargefeat',\n",
       " 'blues.00068.wavlmlargefeat',\n",
       " 'blues.00069.wavlmlargefeat',\n",
       " 'blues.00070.wavlmlargefeat',\n",
       " 'blues.00071.wavlmlargefeat',\n",
       " 'blues.00072.wavlmlargefeat',\n",
       " 'blues.00073.wavlmlargefeat',\n",
       " 'blues.00074.wavlmlargefeat',\n",
       " 'blues.00075.wavlmlargefeat',\n",
       " 'blues.00076.wavlmlargefeat',\n",
       " 'blues.00077.wavlmlargefeat',\n",
       " 'blues.00078.wavlmlargefeat',\n",
       " 'blues.00079.wavlmlargefeat',\n",
       " 'blues.00080.wavlmlargefeat',\n",
       " 'blues.00081.wavlmlargefeat',\n",
       " 'blues.00082.wavlmlargefeat',\n",
       " 'blues.00083.wavlmlargefeat',\n",
       " 'blues.00084.wavlmlargefeat',\n",
       " 'blues.00085.wavlmlargefeat',\n",
       " 'blues.00086.wavlmlargefeat',\n",
       " 'blues.00087.wavlmlargefeat',\n",
       " 'blues.00088.wavlmlargefeat',\n",
       " 'blues.00089.wavlmlargefeat',\n",
       " 'blues.00090.wavlmlargefeat',\n",
       " 'blues.00091.wavlmlargefeat',\n",
       " 'blues.00092.wavlmlargefeat',\n",
       " 'blues.00093.wavlmlargefeat',\n",
       " 'blues.00094.wavlmlargefeat',\n",
       " 'blues.00095.wavlmlargefeat',\n",
       " 'blues.00096.wavlmlargefeat',\n",
       " 'blues.00097.wavlmlargefeat',\n",
       " 'blues.00098.wavlmlargefeat',\n",
       " 'blues.00099.wavlmlargefeat',\n",
       " 'classical.00000.wavlmlargefeat',\n",
       " 'classical.00001.wavlmlargefeat',\n",
       " 'classical.00002.wavlmlargefeat',\n",
       " 'classical.00003.wavlmlargefeat',\n",
       " 'classical.00004.wavlmlargefeat',\n",
       " 'classical.00005.wavlmlargefeat',\n",
       " 'classical.00006.wavlmlargefeat',\n",
       " 'classical.00007.wavlmlargefeat',\n",
       " 'classical.00008.wavlmlargefeat',\n",
       " 'classical.00009.wavlmlargefeat',\n",
       " 'classical.00010.wavlmlargefeat',\n",
       " 'classical.00011.wavlmlargefeat',\n",
       " 'classical.00012.wavlmlargefeat',\n",
       " 'classical.00013.wavlmlargefeat',\n",
       " 'classical.00014.wavlmlargefeat',\n",
       " 'classical.00015.wavlmlargefeat',\n",
       " 'classical.00016.wavlmlargefeat',\n",
       " 'classical.00017.wavlmlargefeat',\n",
       " 'classical.00018.wavlmlargefeat',\n",
       " 'classical.00019.wavlmlargefeat',\n",
       " 'classical.00020.wavlmlargefeat',\n",
       " 'classical.00021.wavlmlargefeat',\n",
       " 'classical.00022.wavlmlargefeat',\n",
       " 'classical.00023.wavlmlargefeat',\n",
       " 'classical.00024.wavlmlargefeat',\n",
       " 'classical.00025.wavlmlargefeat',\n",
       " 'classical.00026.wavlmlargefeat',\n",
       " 'classical.00027.wavlmlargefeat',\n",
       " 'classical.00028.wavlmlargefeat',\n",
       " 'classical.00029.wavlmlargefeat',\n",
       " 'classical.00030.wavlmlargefeat',\n",
       " 'classical.00031.wavlmlargefeat',\n",
       " 'classical.00032.wavlmlargefeat',\n",
       " 'classical.00033.wavlmlargefeat',\n",
       " 'classical.00034.wavlmlargefeat',\n",
       " 'classical.00035.wavlmlargefeat',\n",
       " 'classical.00036.wavlmlargefeat',\n",
       " 'classical.00037.wavlmlargefeat',\n",
       " 'classical.00038.wavlmlargefeat',\n",
       " 'classical.00039.wavlmlargefeat',\n",
       " 'classical.00040.wavlmlargefeat',\n",
       " 'classical.00041.wavlmlargefeat',\n",
       " 'classical.00042.wavlmlargefeat',\n",
       " 'classical.00043.wavlmlargefeat',\n",
       " 'classical.00044.wavlmlargefeat',\n",
       " 'classical.00045.wavlmlargefeat',\n",
       " 'classical.00046.wavlmlargefeat',\n",
       " 'classical.00047.wavlmlargefeat',\n",
       " 'classical.00048.wavlmlargefeat',\n",
       " 'classical.00049.wavlmlargefeat',\n",
       " 'classical.00050.wavlmlargefeat',\n",
       " 'classical.00051.wavlmlargefeat',\n",
       " 'classical.00052.wavlmlargefeat',\n",
       " 'classical.00053.wavlmlargefeat',\n",
       " 'classical.00054.wavlmlargefeat',\n",
       " 'classical.00055.wavlmlargefeat',\n",
       " 'classical.00056.wavlmlargefeat',\n",
       " 'classical.00057.wavlmlargefeat',\n",
       " 'classical.00058.wavlmlargefeat',\n",
       " 'classical.00059.wavlmlargefeat',\n",
       " 'classical.00060.wavlmlargefeat',\n",
       " 'classical.00061.wavlmlargefeat',\n",
       " 'classical.00062.wavlmlargefeat',\n",
       " 'classical.00063.wavlmlargefeat',\n",
       " 'classical.00064.wavlmlargefeat',\n",
       " 'classical.00065.wavlmlargefeat',\n",
       " 'classical.00066.wavlmlargefeat',\n",
       " 'classical.00067.wavlmlargefeat',\n",
       " 'classical.00068.wavlmlargefeat',\n",
       " 'classical.00069.wavlmlargefeat',\n",
       " 'classical.00070.wavlmlargefeat',\n",
       " 'classical.00071.wavlmlargefeat',\n",
       " 'classical.00072.wavlmlargefeat',\n",
       " 'classical.00073.wavlmlargefeat',\n",
       " 'classical.00074.wavlmlargefeat',\n",
       " 'classical.00075.wavlmlargefeat',\n",
       " 'classical.00076.wavlmlargefeat',\n",
       " 'classical.00077.wavlmlargefeat',\n",
       " 'classical.00078.wavlmlargefeat',\n",
       " 'classical.00079.wavlmlargefeat',\n",
       " 'classical.00080.wavlmlargefeat',\n",
       " 'classical.00081.wavlmlargefeat',\n",
       " 'classical.00082.wavlmlargefeat',\n",
       " 'classical.00083.wavlmlargefeat',\n",
       " 'classical.00084.wavlmlargefeat',\n",
       " 'classical.00085.wavlmlargefeat',\n",
       " 'classical.00086.wavlmlargefeat',\n",
       " 'classical.00087.wavlmlargefeat',\n",
       " 'classical.00088.wavlmlargefeat',\n",
       " 'classical.00089.wavlmlargefeat',\n",
       " 'classical.00090.wavlmlargefeat',\n",
       " 'classical.00091.wavlmlargefeat',\n",
       " 'classical.00092.wavlmlargefeat',\n",
       " 'classical.00093.wavlmlargefeat',\n",
       " 'classical.00094.wavlmlargefeat',\n",
       " 'classical.00095.wavlmlargefeat',\n",
       " 'classical.00096.wavlmlargefeat',\n",
       " 'classical.00097.wavlmlargefeat',\n",
       " 'classical.00098.wavlmlargefeat',\n",
       " 'classical.00099.wavlmlargefeat',\n",
       " 'country.00000.wavlmlargefeat',\n",
       " 'country.00001.wavlmlargefeat',\n",
       " 'country.00002.wavlmlargefeat',\n",
       " 'country.00003.wavlmlargefeat',\n",
       " 'country.00004.wavlmlargefeat',\n",
       " 'country.00005.wavlmlargefeat',\n",
       " 'country.00006.wavlmlargefeat',\n",
       " 'country.00007.wavlmlargefeat',\n",
       " 'country.00008.wavlmlargefeat',\n",
       " 'country.00009.wavlmlargefeat',\n",
       " 'country.00010.wavlmlargefeat',\n",
       " 'country.00011.wavlmlargefeat',\n",
       " 'country.00012.wavlmlargefeat',\n",
       " 'country.00013.wavlmlargefeat',\n",
       " 'country.00014.wavlmlargefeat',\n",
       " 'country.00015.wavlmlargefeat',\n",
       " 'country.00016.wavlmlargefeat',\n",
       " 'country.00017.wavlmlargefeat',\n",
       " 'country.00018.wavlmlargefeat',\n",
       " 'country.00019.wavlmlargefeat',\n",
       " 'country.00020.wavlmlargefeat',\n",
       " 'country.00021.wavlmlargefeat',\n",
       " 'country.00022.wavlmlargefeat',\n",
       " 'country.00023.wavlmlargefeat',\n",
       " 'country.00024.wavlmlargefeat',\n",
       " 'country.00025.wavlmlargefeat',\n",
       " 'country.00026.wavlmlargefeat',\n",
       " 'country.00027.wavlmlargefeat',\n",
       " 'country.00028.wavlmlargefeat',\n",
       " 'country.00029.wavlmlargefeat',\n",
       " 'country.00030.wavlmlargefeat',\n",
       " 'country.00031.wavlmlargefeat',\n",
       " 'country.00032.wavlmlargefeat',\n",
       " 'country.00033.wavlmlargefeat',\n",
       " 'country.00034.wavlmlargefeat',\n",
       " 'country.00035.wavlmlargefeat',\n",
       " 'country.00036.wavlmlargefeat',\n",
       " 'country.00037.wavlmlargefeat',\n",
       " 'country.00038.wavlmlargefeat',\n",
       " 'country.00039.wavlmlargefeat',\n",
       " 'country.00040.wavlmlargefeat',\n",
       " 'country.00041.wavlmlargefeat',\n",
       " 'country.00042.wavlmlargefeat',\n",
       " 'country.00043.wavlmlargefeat',\n",
       " 'country.00044.wavlmlargefeat',\n",
       " 'country.00045.wavlmlargefeat',\n",
       " 'country.00046.wavlmlargefeat',\n",
       " 'country.00047.wavlmlargefeat',\n",
       " 'country.00048.wavlmlargefeat',\n",
       " 'country.00049.wavlmlargefeat',\n",
       " 'country.00050.wavlmlargefeat',\n",
       " 'country.00051.wavlmlargefeat',\n",
       " 'country.00052.wavlmlargefeat',\n",
       " 'country.00053.wavlmlargefeat',\n",
       " 'country.00054.wavlmlargefeat',\n",
       " 'country.00055.wavlmlargefeat',\n",
       " 'country.00056.wavlmlargefeat',\n",
       " 'country.00057.wavlmlargefeat',\n",
       " 'country.00058.wavlmlargefeat',\n",
       " 'country.00059.wavlmlargefeat',\n",
       " 'country.00060.wavlmlargefeat',\n",
       " 'country.00061.wavlmlargefeat',\n",
       " 'country.00062.wavlmlargefeat',\n",
       " 'country.00063.wavlmlargefeat',\n",
       " 'country.00064.wavlmlargefeat',\n",
       " 'country.00065.wavlmlargefeat',\n",
       " 'country.00066.wavlmlargefeat',\n",
       " 'country.00067.wavlmlargefeat',\n",
       " 'country.00068.wavlmlargefeat',\n",
       " 'country.00069.wavlmlargefeat',\n",
       " 'country.00070.wavlmlargefeat',\n",
       " 'country.00071.wavlmlargefeat',\n",
       " 'country.00072.wavlmlargefeat',\n",
       " 'country.00073.wavlmlargefeat',\n",
       " 'country.00074.wavlmlargefeat',\n",
       " 'country.00075.wavlmlargefeat',\n",
       " 'country.00076.wavlmlargefeat',\n",
       " 'country.00077.wavlmlargefeat',\n",
       " 'country.00078.wavlmlargefeat',\n",
       " 'country.00079.wavlmlargefeat',\n",
       " 'country.00080.wavlmlargefeat',\n",
       " 'country.00081.wavlmlargefeat',\n",
       " 'country.00082.wavlmlargefeat',\n",
       " 'country.00083.wavlmlargefeat',\n",
       " 'country.00084.wavlmlargefeat',\n",
       " 'country.00085.wavlmlargefeat',\n",
       " 'country.00086.wavlmlargefeat',\n",
       " 'country.00087.wavlmlargefeat',\n",
       " 'country.00088.wavlmlargefeat',\n",
       " 'country.00089.wavlmlargefeat',\n",
       " 'country.00090.wavlmlargefeat',\n",
       " 'country.00091.wavlmlargefeat',\n",
       " 'country.00092.wavlmlargefeat',\n",
       " 'country.00093.wavlmlargefeat',\n",
       " 'country.00094.wavlmlargefeat',\n",
       " 'country.00095.wavlmlargefeat',\n",
       " 'country.00096.wavlmlargefeat',\n",
       " 'country.00097.wavlmlargefeat',\n",
       " 'country.00098.wavlmlargefeat',\n",
       " 'country.00099.wavlmlargefeat',\n",
       " 'disco.00000.wavlmlargefeat',\n",
       " 'disco.00001.wavlmlargefeat',\n",
       " 'disco.00002.wavlmlargefeat',\n",
       " 'disco.00003.wavlmlargefeat',\n",
       " 'disco.00004.wavlmlargefeat',\n",
       " 'disco.00005.wavlmlargefeat',\n",
       " 'disco.00006.wavlmlargefeat',\n",
       " 'disco.00007.wavlmlargefeat',\n",
       " 'disco.00008.wavlmlargefeat',\n",
       " 'disco.00009.wavlmlargefeat',\n",
       " 'disco.00010.wavlmlargefeat',\n",
       " 'disco.00011.wavlmlargefeat',\n",
       " 'disco.00012.wavlmlargefeat',\n",
       " 'disco.00013.wavlmlargefeat',\n",
       " 'disco.00014.wavlmlargefeat',\n",
       " 'disco.00015.wavlmlargefeat',\n",
       " 'disco.00016.wavlmlargefeat',\n",
       " 'disco.00017.wavlmlargefeat',\n",
       " 'disco.00018.wavlmlargefeat',\n",
       " 'disco.00019.wavlmlargefeat',\n",
       " 'disco.00020.wavlmlargefeat',\n",
       " 'disco.00021.wavlmlargefeat',\n",
       " 'disco.00022.wavlmlargefeat',\n",
       " 'disco.00023.wavlmlargefeat',\n",
       " 'disco.00024.wavlmlargefeat',\n",
       " 'disco.00025.wavlmlargefeat',\n",
       " 'disco.00026.wavlmlargefeat',\n",
       " 'disco.00027.wavlmlargefeat',\n",
       " 'disco.00028.wavlmlargefeat',\n",
       " 'disco.00029.wavlmlargefeat',\n",
       " 'disco.00030.wavlmlargefeat',\n",
       " 'disco.00031.wavlmlargefeat',\n",
       " 'disco.00032.wavlmlargefeat',\n",
       " 'disco.00033.wavlmlargefeat',\n",
       " 'disco.00034.wavlmlargefeat',\n",
       " 'disco.00035.wavlmlargefeat',\n",
       " 'disco.00036.wavlmlargefeat',\n",
       " 'disco.00037.wavlmlargefeat',\n",
       " 'disco.00038.wavlmlargefeat',\n",
       " 'disco.00039.wavlmlargefeat',\n",
       " 'disco.00040.wavlmlargefeat',\n",
       " 'disco.00041.wavlmlargefeat',\n",
       " 'disco.00042.wavlmlargefeat',\n",
       " 'disco.00043.wavlmlargefeat',\n",
       " 'disco.00044.wavlmlargefeat',\n",
       " 'disco.00045.wavlmlargefeat',\n",
       " 'disco.00046.wavlmlargefeat',\n",
       " 'disco.00047.wavlmlargefeat',\n",
       " 'disco.00048.wavlmlargefeat',\n",
       " 'disco.00049.wavlmlargefeat',\n",
       " 'disco.00050.wavlmlargefeat',\n",
       " 'disco.00051.wavlmlargefeat',\n",
       " 'disco.00052.wavlmlargefeat',\n",
       " 'disco.00053.wavlmlargefeat',\n",
       " 'disco.00054.wavlmlargefeat',\n",
       " 'disco.00055.wavlmlargefeat',\n",
       " 'disco.00056.wavlmlargefeat',\n",
       " 'disco.00057.wavlmlargefeat',\n",
       " 'disco.00058.wavlmlargefeat',\n",
       " 'disco.00059.wavlmlargefeat',\n",
       " 'disco.00060.wavlmlargefeat',\n",
       " 'disco.00061.wavlmlargefeat',\n",
       " 'disco.00062.wavlmlargefeat',\n",
       " 'disco.00063.wavlmlargefeat',\n",
       " 'disco.00064.wavlmlargefeat',\n",
       " 'disco.00065.wavlmlargefeat',\n",
       " 'disco.00066.wavlmlargefeat',\n",
       " 'disco.00067.wavlmlargefeat',\n",
       " 'disco.00068.wavlmlargefeat',\n",
       " 'disco.00069.wavlmlargefeat',\n",
       " 'disco.00070.wavlmlargefeat',\n",
       " 'disco.00071.wavlmlargefeat',\n",
       " 'disco.00072.wavlmlargefeat',\n",
       " 'disco.00073.wavlmlargefeat',\n",
       " 'disco.00074.wavlmlargefeat',\n",
       " 'disco.00075.wavlmlargefeat',\n",
       " 'disco.00076.wavlmlargefeat',\n",
       " 'disco.00077.wavlmlargefeat',\n",
       " 'disco.00078.wavlmlargefeat',\n",
       " 'disco.00079.wavlmlargefeat',\n",
       " 'disco.00080.wavlmlargefeat',\n",
       " 'disco.00081.wavlmlargefeat',\n",
       " 'disco.00082.wavlmlargefeat',\n",
       " 'disco.00083.wavlmlargefeat',\n",
       " 'disco.00084.wavlmlargefeat',\n",
       " 'disco.00085.wavlmlargefeat',\n",
       " 'disco.00086.wavlmlargefeat',\n",
       " 'disco.00087.wavlmlargefeat',\n",
       " 'disco.00088.wavlmlargefeat',\n",
       " 'disco.00089.wavlmlargefeat',\n",
       " 'disco.00090.wavlmlargefeat',\n",
       " 'disco.00091.wavlmlargefeat',\n",
       " 'disco.00092.wavlmlargefeat',\n",
       " 'disco.00093.wavlmlargefeat',\n",
       " 'disco.00094.wavlmlargefeat',\n",
       " 'disco.00095.wavlmlargefeat',\n",
       " 'disco.00096.wavlmlargefeat',\n",
       " 'disco.00097.wavlmlargefeat',\n",
       " 'disco.00098.wavlmlargefeat',\n",
       " 'disco.00099.wavlmlargefeat',\n",
       " 'hiphop.00000.wavlmlargefeat',\n",
       " 'hiphop.00001.wavlmlargefeat',\n",
       " 'hiphop.00002.wavlmlargefeat',\n",
       " 'hiphop.00003.wavlmlargefeat',\n",
       " 'hiphop.00004.wavlmlargefeat',\n",
       " 'hiphop.00005.wavlmlargefeat',\n",
       " 'hiphop.00006.wavlmlargefeat',\n",
       " 'hiphop.00007.wavlmlargefeat',\n",
       " 'hiphop.00008.wavlmlargefeat',\n",
       " 'hiphop.00009.wavlmlargefeat',\n",
       " 'hiphop.00010.wavlmlargefeat',\n",
       " 'hiphop.00011.wavlmlargefeat',\n",
       " 'hiphop.00012.wavlmlargefeat',\n",
       " 'hiphop.00013.wavlmlargefeat',\n",
       " 'hiphop.00014.wavlmlargefeat',\n",
       " 'hiphop.00015.wavlmlargefeat',\n",
       " 'hiphop.00016.wavlmlargefeat',\n",
       " 'hiphop.00017.wavlmlargefeat',\n",
       " 'hiphop.00018.wavlmlargefeat',\n",
       " 'hiphop.00019.wavlmlargefeat',\n",
       " 'hiphop.00020.wavlmlargefeat',\n",
       " 'hiphop.00021.wavlmlargefeat',\n",
       " 'hiphop.00022.wavlmlargefeat',\n",
       " 'hiphop.00023.wavlmlargefeat',\n",
       " 'hiphop.00024.wavlmlargefeat',\n",
       " 'hiphop.00025.wavlmlargefeat',\n",
       " 'hiphop.00026.wavlmlargefeat',\n",
       " 'hiphop.00027.wavlmlargefeat',\n",
       " 'hiphop.00028.wavlmlargefeat',\n",
       " 'hiphop.00029.wavlmlargefeat',\n",
       " 'hiphop.00030.wavlmlargefeat',\n",
       " 'hiphop.00031.wavlmlargefeat',\n",
       " 'hiphop.00032.wavlmlargefeat',\n",
       " 'hiphop.00033.wavlmlargefeat',\n",
       " 'hiphop.00034.wavlmlargefeat',\n",
       " 'hiphop.00035.wavlmlargefeat',\n",
       " 'hiphop.00036.wavlmlargefeat',\n",
       " 'hiphop.00037.wavlmlargefeat',\n",
       " 'hiphop.00038.wavlmlargefeat',\n",
       " 'hiphop.00039.wavlmlargefeat',\n",
       " 'hiphop.00040.wavlmlargefeat',\n",
       " 'hiphop.00041.wavlmlargefeat',\n",
       " 'hiphop.00042.wavlmlargefeat',\n",
       " 'hiphop.00043.wavlmlargefeat',\n",
       " 'hiphop.00044.wavlmlargefeat',\n",
       " 'hiphop.00045.wavlmlargefeat',\n",
       " 'hiphop.00046.wavlmlargefeat',\n",
       " 'hiphop.00047.wavlmlargefeat',\n",
       " 'hiphop.00048.wavlmlargefeat',\n",
       " 'hiphop.00049.wavlmlargefeat',\n",
       " 'hiphop.00050.wavlmlargefeat',\n",
       " 'hiphop.00051.wavlmlargefeat',\n",
       " 'hiphop.00052.wavlmlargefeat',\n",
       " 'hiphop.00053.wavlmlargefeat',\n",
       " 'hiphop.00054.wavlmlargefeat',\n",
       " 'hiphop.00055.wavlmlargefeat',\n",
       " 'hiphop.00056.wavlmlargefeat',\n",
       " 'hiphop.00057.wavlmlargefeat',\n",
       " 'hiphop.00058.wavlmlargefeat',\n",
       " 'hiphop.00059.wavlmlargefeat',\n",
       " 'hiphop.00060.wavlmlargefeat',\n",
       " 'hiphop.00061.wavlmlargefeat',\n",
       " 'hiphop.00062.wavlmlargefeat',\n",
       " 'hiphop.00063.wavlmlargefeat',\n",
       " 'hiphop.00064.wavlmlargefeat',\n",
       " 'hiphop.00065.wavlmlargefeat',\n",
       " 'hiphop.00066.wavlmlargefeat',\n",
       " 'hiphop.00067.wavlmlargefeat',\n",
       " 'hiphop.00068.wavlmlargefeat',\n",
       " 'hiphop.00069.wavlmlargefeat',\n",
       " 'hiphop.00070.wavlmlargefeat',\n",
       " 'hiphop.00071.wavlmlargefeat',\n",
       " 'hiphop.00072.wavlmlargefeat',\n",
       " 'hiphop.00073.wavlmlargefeat',\n",
       " 'hiphop.00074.wavlmlargefeat',\n",
       " 'hiphop.00075.wavlmlargefeat',\n",
       " 'hiphop.00076.wavlmlargefeat',\n",
       " 'hiphop.00077.wavlmlargefeat',\n",
       " 'hiphop.00078.wavlmlargefeat',\n",
       " 'hiphop.00079.wavlmlargefeat',\n",
       " 'hiphop.00080.wavlmlargefeat',\n",
       " 'hiphop.00081.wavlmlargefeat',\n",
       " 'hiphop.00082.wavlmlargefeat',\n",
       " 'hiphop.00083.wavlmlargefeat',\n",
       " 'hiphop.00084.wavlmlargefeat',\n",
       " 'hiphop.00085.wavlmlargefeat',\n",
       " 'hiphop.00086.wavlmlargefeat',\n",
       " 'hiphop.00087.wavlmlargefeat',\n",
       " 'hiphop.00088.wavlmlargefeat',\n",
       " 'hiphop.00089.wavlmlargefeat',\n",
       " 'hiphop.00090.wavlmlargefeat',\n",
       " 'hiphop.00091.wavlmlargefeat',\n",
       " 'hiphop.00092.wavlmlargefeat',\n",
       " 'hiphop.00093.wavlmlargefeat',\n",
       " 'hiphop.00094.wavlmlargefeat',\n",
       " 'hiphop.00095.wavlmlargefeat',\n",
       " 'hiphop.00096.wavlmlargefeat',\n",
       " 'hiphop.00097.wavlmlargefeat',\n",
       " 'hiphop.00098.wavlmlargefeat',\n",
       " 'hiphop.00099.wavlmlargefeat',\n",
       " 'jazz.00000.wavlmlargefeat',\n",
       " 'jazz.00001.wavlmlargefeat',\n",
       " 'jazz.00002.wavlmlargefeat',\n",
       " 'jazz.00003.wavlmlargefeat',\n",
       " 'jazz.00004.wavlmlargefeat',\n",
       " 'jazz.00005.wavlmlargefeat',\n",
       " 'jazz.00006.wavlmlargefeat',\n",
       " 'jazz.00007.wavlmlargefeat',\n",
       " 'jazz.00008.wavlmlargefeat',\n",
       " 'jazz.00009.wavlmlargefeat',\n",
       " 'jazz.00010.wavlmlargefeat',\n",
       " 'jazz.00011.wavlmlargefeat',\n",
       " 'jazz.00012.wavlmlargefeat',\n",
       " 'jazz.00013.wavlmlargefeat',\n",
       " 'jazz.00014.wavlmlargefeat',\n",
       " 'jazz.00015.wavlmlargefeat',\n",
       " 'jazz.00016.wavlmlargefeat',\n",
       " 'jazz.00017.wavlmlargefeat',\n",
       " 'jazz.00018.wavlmlargefeat',\n",
       " 'jazz.00019.wavlmlargefeat',\n",
       " 'jazz.00020.wavlmlargefeat',\n",
       " 'jazz.00021.wavlmlargefeat',\n",
       " 'jazz.00022.wavlmlargefeat',\n",
       " 'jazz.00023.wavlmlargefeat',\n",
       " 'jazz.00024.wavlmlargefeat',\n",
       " 'jazz.00025.wavlmlargefeat',\n",
       " 'jazz.00026.wavlmlargefeat',\n",
       " 'jazz.00027.wavlmlargefeat',\n",
       " 'jazz.00028.wavlmlargefeat',\n",
       " 'jazz.00029.wavlmlargefeat',\n",
       " 'jazz.00030.wavlmlargefeat',\n",
       " 'jazz.00031.wavlmlargefeat',\n",
       " 'jazz.00032.wavlmlargefeat',\n",
       " 'jazz.00033.wavlmlargefeat',\n",
       " 'jazz.00034.wavlmlargefeat',\n",
       " 'jazz.00035.wavlmlargefeat',\n",
       " 'jazz.00036.wavlmlargefeat',\n",
       " 'jazz.00037.wavlmlargefeat',\n",
       " 'jazz.00038.wavlmlargefeat',\n",
       " 'jazz.00039.wavlmlargefeat',\n",
       " 'jazz.00040.wavlmlargefeat',\n",
       " 'jazz.00041.wavlmlargefeat',\n",
       " 'jazz.00042.wavlmlargefeat',\n",
       " 'jazz.00043.wavlmlargefeat',\n",
       " 'jazz.00044.wavlmlargefeat',\n",
       " 'jazz.00045.wavlmlargefeat',\n",
       " 'jazz.00046.wavlmlargefeat',\n",
       " 'jazz.00047.wavlmlargefeat',\n",
       " 'jazz.00048.wavlmlargefeat',\n",
       " 'jazz.00049.wavlmlargefeat',\n",
       " 'jazz.00050.wavlmlargefeat',\n",
       " 'jazz.00051.wavlmlargefeat',\n",
       " 'jazz.00052.wavlmlargefeat',\n",
       " 'jazz.00053.wavlmlargefeat',\n",
       " 'jazz.00054.wavlmlargefeat',\n",
       " 'jazz.00055.wavlmlargefeat',\n",
       " 'jazz.00056.wavlmlargefeat',\n",
       " 'jazz.00057.wavlmlargefeat',\n",
       " 'jazz.00058.wavlmlargefeat',\n",
       " 'jazz.00059.wavlmlargefeat',\n",
       " 'jazz.00060.wavlmlargefeat',\n",
       " 'jazz.00061.wavlmlargefeat',\n",
       " 'jazz.00062.wavlmlargefeat',\n",
       " 'jazz.00063.wavlmlargefeat',\n",
       " 'jazz.00064.wavlmlargefeat',\n",
       " 'jazz.00065.wavlmlargefeat',\n",
       " 'jazz.00066.wavlmlargefeat',\n",
       " 'jazz.00067.wavlmlargefeat',\n",
       " 'jazz.00068.wavlmlargefeat',\n",
       " 'jazz.00069.wavlmlargefeat',\n",
       " 'jazz.00070.wavlmlargefeat',\n",
       " 'jazz.00071.wavlmlargefeat',\n",
       " 'jazz.00072.wavlmlargefeat',\n",
       " 'jazz.00073.wavlmlargefeat',\n",
       " 'jazz.00074.wavlmlargefeat',\n",
       " 'jazz.00075.wavlmlargefeat',\n",
       " 'jazz.00076.wavlmlargefeat',\n",
       " 'jazz.00077.wavlmlargefeat',\n",
       " 'jazz.00078.wavlmlargefeat',\n",
       " 'jazz.00079.wavlmlargefeat',\n",
       " 'jazz.00080.wavlmlargefeat',\n",
       " 'jazz.00081.wavlmlargefeat',\n",
       " 'jazz.00082.wavlmlargefeat',\n",
       " 'jazz.00083.wavlmlargefeat',\n",
       " 'jazz.00084.wavlmlargefeat',\n",
       " 'jazz.00085.wavlmlargefeat',\n",
       " 'jazz.00086.wavlmlargefeat',\n",
       " 'jazz.00087.wavlmlargefeat',\n",
       " 'jazz.00088.wavlmlargefeat',\n",
       " 'jazz.00089.wavlmlargefeat',\n",
       " 'jazz.00090.wavlmlargefeat',\n",
       " 'jazz.00091.wavlmlargefeat',\n",
       " 'jazz.00092.wavlmlargefeat',\n",
       " 'jazz.00093.wavlmlargefeat',\n",
       " 'jazz.00094.wavlmlargefeat',\n",
       " 'jazz.00095.wavlmlargefeat',\n",
       " 'jazz.00096.wavlmlargefeat',\n",
       " 'jazz.00097.wavlmlargefeat',\n",
       " 'jazz.00098.wavlmlargefeat',\n",
       " 'jazz.00099.wavlmlargefeat',\n",
       " 'metal.00000.wavlmlargefeat',\n",
       " 'metal.00001.wavlmlargefeat',\n",
       " 'metal.00002.wavlmlargefeat',\n",
       " 'metal.00003.wavlmlargefeat',\n",
       " 'metal.00004.wavlmlargefeat',\n",
       " 'metal.00005.wavlmlargefeat',\n",
       " 'metal.00006.wavlmlargefeat',\n",
       " 'metal.00007.wavlmlargefeat',\n",
       " 'metal.00008.wavlmlargefeat',\n",
       " 'metal.00009.wavlmlargefeat',\n",
       " 'metal.00010.wavlmlargefeat',\n",
       " 'metal.00011.wavlmlargefeat',\n",
       " 'metal.00012.wavlmlargefeat',\n",
       " 'metal.00013.wavlmlargefeat',\n",
       " 'metal.00014.wavlmlargefeat',\n",
       " 'metal.00015.wavlmlargefeat',\n",
       " 'metal.00016.wavlmlargefeat',\n",
       " 'metal.00017.wavlmlargefeat',\n",
       " 'metal.00018.wavlmlargefeat',\n",
       " 'metal.00019.wavlmlargefeat',\n",
       " 'metal.00020.wavlmlargefeat',\n",
       " 'metal.00021.wavlmlargefeat',\n",
       " 'metal.00022.wavlmlargefeat',\n",
       " 'metal.00023.wavlmlargefeat',\n",
       " 'metal.00024.wavlmlargefeat',\n",
       " 'metal.00025.wavlmlargefeat',\n",
       " 'metal.00026.wavlmlargefeat',\n",
       " 'metal.00027.wavlmlargefeat',\n",
       " 'metal.00028.wavlmlargefeat',\n",
       " 'metal.00029.wavlmlargefeat',\n",
       " 'metal.00030.wavlmlargefeat',\n",
       " 'metal.00031.wavlmlargefeat',\n",
       " 'metal.00032.wavlmlargefeat',\n",
       " 'metal.00033.wavlmlargefeat',\n",
       " 'metal.00034.wavlmlargefeat',\n",
       " 'metal.00035.wavlmlargefeat',\n",
       " 'metal.00036.wavlmlargefeat',\n",
       " 'metal.00037.wavlmlargefeat',\n",
       " 'metal.00038.wavlmlargefeat',\n",
       " 'metal.00039.wavlmlargefeat',\n",
       " 'metal.00040.wavlmlargefeat',\n",
       " 'metal.00041.wavlmlargefeat',\n",
       " 'metal.00042.wavlmlargefeat',\n",
       " 'metal.00043.wavlmlargefeat',\n",
       " 'metal.00044.wavlmlargefeat',\n",
       " 'metal.00045.wavlmlargefeat',\n",
       " 'metal.00046.wavlmlargefeat',\n",
       " 'metal.00047.wavlmlargefeat',\n",
       " 'metal.00048.wavlmlargefeat',\n",
       " 'metal.00049.wavlmlargefeat',\n",
       " 'metal.00050.wavlmlargefeat',\n",
       " 'metal.00051.wavlmlargefeat',\n",
       " 'metal.00052.wavlmlargefeat',\n",
       " 'metal.00053.wavlmlargefeat',\n",
       " 'metal.00054.wavlmlargefeat',\n",
       " 'metal.00055.wavlmlargefeat',\n",
       " 'metal.00056.wavlmlargefeat',\n",
       " 'metal.00057.wavlmlargefeat',\n",
       " 'metal.00058.wavlmlargefeat',\n",
       " 'metal.00059.wavlmlargefeat',\n",
       " 'metal.00060.wavlmlargefeat',\n",
       " 'metal.00061.wavlmlargefeat',\n",
       " 'metal.00062.wavlmlargefeat',\n",
       " 'metal.00063.wavlmlargefeat',\n",
       " 'metal.00064.wavlmlargefeat',\n",
       " 'metal.00065.wavlmlargefeat',\n",
       " 'metal.00066.wavlmlargefeat',\n",
       " 'metal.00067.wavlmlargefeat',\n",
       " 'metal.00068.wavlmlargefeat',\n",
       " 'metal.00069.wavlmlargefeat',\n",
       " 'metal.00070.wavlmlargefeat',\n",
       " 'metal.00071.wavlmlargefeat',\n",
       " 'metal.00072.wavlmlargefeat',\n",
       " 'metal.00073.wavlmlargefeat',\n",
       " 'metal.00074.wavlmlargefeat',\n",
       " 'metal.00075.wavlmlargefeat',\n",
       " 'metal.00076.wavlmlargefeat',\n",
       " 'metal.00077.wavlmlargefeat',\n",
       " 'metal.00078.wavlmlargefeat',\n",
       " 'metal.00079.wavlmlargefeat',\n",
       " 'metal.00080.wavlmlargefeat',\n",
       " 'metal.00081.wavlmlargefeat',\n",
       " 'metal.00082.wavlmlargefeat',\n",
       " 'metal.00083.wavlmlargefeat',\n",
       " 'metal.00084.wavlmlargefeat',\n",
       " 'metal.00085.wavlmlargefeat',\n",
       " 'metal.00086.wavlmlargefeat',\n",
       " 'metal.00087.wavlmlargefeat',\n",
       " 'metal.00088.wavlmlargefeat',\n",
       " 'metal.00089.wavlmlargefeat',\n",
       " 'metal.00090.wavlmlargefeat',\n",
       " 'metal.00091.wavlmlargefeat',\n",
       " 'metal.00092.wavlmlargefeat',\n",
       " 'metal.00093.wavlmlargefeat',\n",
       " 'metal.00094.wavlmlargefeat',\n",
       " 'metal.00095.wavlmlargefeat',\n",
       " 'metal.00096.wavlmlargefeat',\n",
       " 'metal.00097.wavlmlargefeat',\n",
       " 'metal.00098.wavlmlargefeat',\n",
       " 'metal.00099.wavlmlargefeat',\n",
       " 'pop.00000.wavlmlargefeat',\n",
       " 'pop.00001.wavlmlargefeat',\n",
       " 'pop.00002.wavlmlargefeat',\n",
       " 'pop.00003.wavlmlargefeat',\n",
       " 'pop.00004.wavlmlargefeat',\n",
       " 'pop.00005.wavlmlargefeat',\n",
       " 'pop.00006.wavlmlargefeat',\n",
       " 'pop.00007.wavlmlargefeat',\n",
       " 'pop.00008.wavlmlargefeat',\n",
       " 'pop.00009.wavlmlargefeat',\n",
       " 'pop.00010.wavlmlargefeat',\n",
       " 'pop.00011.wavlmlargefeat',\n",
       " 'pop.00012.wavlmlargefeat',\n",
       " 'pop.00013.wavlmlargefeat',\n",
       " 'pop.00014.wavlmlargefeat',\n",
       " 'pop.00015.wavlmlargefeat',\n",
       " 'pop.00016.wavlmlargefeat',\n",
       " 'pop.00017.wavlmlargefeat',\n",
       " 'pop.00018.wavlmlargefeat',\n",
       " 'pop.00019.wavlmlargefeat',\n",
       " 'pop.00020.wavlmlargefeat',\n",
       " 'pop.00021.wavlmlargefeat',\n",
       " 'pop.00022.wavlmlargefeat',\n",
       " 'pop.00023.wavlmlargefeat',\n",
       " 'pop.00024.wavlmlargefeat',\n",
       " 'pop.00025.wavlmlargefeat',\n",
       " 'pop.00026.wavlmlargefeat',\n",
       " 'pop.00027.wavlmlargefeat',\n",
       " 'pop.00028.wavlmlargefeat',\n",
       " 'pop.00029.wavlmlargefeat',\n",
       " 'pop.00030.wavlmlargefeat',\n",
       " 'pop.00031.wavlmlargefeat',\n",
       " 'pop.00032.wavlmlargefeat',\n",
       " 'pop.00033.wavlmlargefeat',\n",
       " 'pop.00034.wavlmlargefeat',\n",
       " 'pop.00035.wavlmlargefeat',\n",
       " 'pop.00036.wavlmlargefeat',\n",
       " 'pop.00037.wavlmlargefeat',\n",
       " 'pop.00038.wavlmlargefeat',\n",
       " 'pop.00039.wavlmlargefeat',\n",
       " 'pop.00040.wavlmlargefeat',\n",
       " 'pop.00041.wavlmlargefeat',\n",
       " 'pop.00042.wavlmlargefeat',\n",
       " 'pop.00043.wavlmlargefeat',\n",
       " 'pop.00044.wavlmlargefeat',\n",
       " 'pop.00045.wavlmlargefeat',\n",
       " 'pop.00046.wavlmlargefeat',\n",
       " 'pop.00047.wavlmlargefeat',\n",
       " 'pop.00048.wavlmlargefeat',\n",
       " 'pop.00049.wavlmlargefeat',\n",
       " 'pop.00050.wavlmlargefeat',\n",
       " 'pop.00051.wavlmlargefeat',\n",
       " 'pop.00052.wavlmlargefeat',\n",
       " 'pop.00053.wavlmlargefeat',\n",
       " 'pop.00054.wavlmlargefeat',\n",
       " 'pop.00055.wavlmlargefeat',\n",
       " 'pop.00056.wavlmlargefeat',\n",
       " 'pop.00057.wavlmlargefeat',\n",
       " 'pop.00058.wavlmlargefeat',\n",
       " 'pop.00059.wavlmlargefeat',\n",
       " 'pop.00060.wavlmlargefeat',\n",
       " 'pop.00061.wavlmlargefeat',\n",
       " 'pop.00062.wavlmlargefeat',\n",
       " 'pop.00063.wavlmlargefeat',\n",
       " 'pop.00064.wavlmlargefeat',\n",
       " 'pop.00065.wavlmlargefeat',\n",
       " 'pop.00066.wavlmlargefeat',\n",
       " 'pop.00067.wavlmlargefeat',\n",
       " 'pop.00068.wavlmlargefeat',\n",
       " 'pop.00069.wavlmlargefeat',\n",
       " 'pop.00070.wavlmlargefeat',\n",
       " 'pop.00071.wavlmlargefeat',\n",
       " 'pop.00072.wavlmlargefeat',\n",
       " 'pop.00073.wavlmlargefeat',\n",
       " 'pop.00074.wavlmlargefeat',\n",
       " 'pop.00075.wavlmlargefeat',\n",
       " 'pop.00076.wavlmlargefeat',\n",
       " 'pop.00077.wavlmlargefeat',\n",
       " 'pop.00078.wavlmlargefeat',\n",
       " 'pop.00079.wavlmlargefeat',\n",
       " 'pop.00080.wavlmlargefeat',\n",
       " 'pop.00081.wavlmlargefeat',\n",
       " 'pop.00082.wavlmlargefeat',\n",
       " 'pop.00083.wavlmlargefeat',\n",
       " 'pop.00084.wavlmlargefeat',\n",
       " 'pop.00085.wavlmlargefeat',\n",
       " 'pop.00086.wavlmlargefeat',\n",
       " 'pop.00087.wavlmlargefeat',\n",
       " 'pop.00088.wavlmlargefeat',\n",
       " 'pop.00089.wavlmlargefeat',\n",
       " 'pop.00090.wavlmlargefeat',\n",
       " 'pop.00091.wavlmlargefeat',\n",
       " 'pop.00092.wavlmlargefeat',\n",
       " 'pop.00093.wavlmlargefeat',\n",
       " 'pop.00094.wavlmlargefeat',\n",
       " 'pop.00095.wavlmlargefeat',\n",
       " 'pop.00096.wavlmlargefeat',\n",
       " 'pop.00097.wavlmlargefeat',\n",
       " 'pop.00098.wavlmlargefeat',\n",
       " 'pop.00099.wavlmlargefeat',\n",
       " 'reggae.00000.wavlmlargefeat',\n",
       " 'reggae.00001.wavlmlargefeat',\n",
       " 'reggae.00002.wavlmlargefeat',\n",
       " 'reggae.00003.wavlmlargefeat',\n",
       " 'reggae.00004.wavlmlargefeat',\n",
       " 'reggae.00005.wavlmlargefeat',\n",
       " 'reggae.00006.wavlmlargefeat',\n",
       " 'reggae.00007.wavlmlargefeat',\n",
       " 'reggae.00008.wavlmlargefeat',\n",
       " 'reggae.00009.wavlmlargefeat',\n",
       " 'reggae.00010.wavlmlargefeat',\n",
       " 'reggae.00011.wavlmlargefeat',\n",
       " 'reggae.00012.wavlmlargefeat',\n",
       " 'reggae.00013.wavlmlargefeat',\n",
       " 'reggae.00014.wavlmlargefeat',\n",
       " 'reggae.00015.wavlmlargefeat',\n",
       " 'reggae.00016.wavlmlargefeat',\n",
       " 'reggae.00017.wavlmlargefeat',\n",
       " 'reggae.00018.wavlmlargefeat',\n",
       " 'reggae.00019.wavlmlargefeat',\n",
       " 'reggae.00020.wavlmlargefeat',\n",
       " 'reggae.00021.wavlmlargefeat',\n",
       " 'reggae.00022.wavlmlargefeat',\n",
       " 'reggae.00023.wavlmlargefeat',\n",
       " 'reggae.00024.wavlmlargefeat',\n",
       " 'reggae.00025.wavlmlargefeat',\n",
       " 'reggae.00026.wavlmlargefeat',\n",
       " 'reggae.00027.wavlmlargefeat',\n",
       " 'reggae.00028.wavlmlargefeat',\n",
       " 'reggae.00029.wavlmlargefeat',\n",
       " 'reggae.00030.wavlmlargefeat',\n",
       " 'reggae.00031.wavlmlargefeat',\n",
       " 'reggae.00032.wavlmlargefeat',\n",
       " 'reggae.00033.wavlmlargefeat',\n",
       " 'reggae.00034.wavlmlargefeat',\n",
       " 'reggae.00035.wavlmlargefeat',\n",
       " 'reggae.00036.wavlmlargefeat',\n",
       " 'reggae.00037.wavlmlargefeat',\n",
       " 'reggae.00038.wavlmlargefeat',\n",
       " 'reggae.00039.wavlmlargefeat',\n",
       " 'reggae.00040.wavlmlargefeat',\n",
       " 'reggae.00041.wavlmlargefeat',\n",
       " 'reggae.00042.wavlmlargefeat',\n",
       " 'reggae.00043.wavlmlargefeat',\n",
       " 'reggae.00044.wavlmlargefeat',\n",
       " 'reggae.00045.wavlmlargefeat',\n",
       " 'reggae.00046.wavlmlargefeat',\n",
       " 'reggae.00047.wavlmlargefeat',\n",
       " 'reggae.00048.wavlmlargefeat',\n",
       " 'reggae.00049.wavlmlargefeat',\n",
       " 'reggae.00050.wavlmlargefeat',\n",
       " 'reggae.00051.wavlmlargefeat',\n",
       " 'reggae.00052.wavlmlargefeat',\n",
       " 'reggae.00053.wavlmlargefeat',\n",
       " 'reggae.00054.wavlmlargefeat',\n",
       " 'reggae.00055.wavlmlargefeat',\n",
       " 'reggae.00056.wavlmlargefeat',\n",
       " 'reggae.00057.wavlmlargefeat',\n",
       " 'reggae.00058.wavlmlargefeat',\n",
       " 'reggae.00059.wavlmlargefeat',\n",
       " 'reggae.00060.wavlmlargefeat',\n",
       " 'reggae.00061.wavlmlargefeat',\n",
       " 'reggae.00062.wavlmlargefeat',\n",
       " 'reggae.00063.wavlmlargefeat',\n",
       " 'reggae.00064.wavlmlargefeat',\n",
       " 'reggae.00065.wavlmlargefeat',\n",
       " 'reggae.00066.wavlmlargefeat',\n",
       " 'reggae.00067.wavlmlargefeat',\n",
       " 'reggae.00068.wavlmlargefeat',\n",
       " 'reggae.00069.wavlmlargefeat',\n",
       " 'reggae.00070.wavlmlargefeat',\n",
       " 'reggae.00071.wavlmlargefeat',\n",
       " 'reggae.00072.wavlmlargefeat',\n",
       " 'reggae.00073.wavlmlargefeat',\n",
       " 'reggae.00074.wavlmlargefeat',\n",
       " 'reggae.00075.wavlmlargefeat',\n",
       " 'reggae.00076.wavlmlargefeat',\n",
       " 'reggae.00077.wavlmlargefeat',\n",
       " 'reggae.00078.wavlmlargefeat',\n",
       " 'reggae.00079.wavlmlargefeat',\n",
       " 'reggae.00080.wavlmlargefeat',\n",
       " 'reggae.00081.wavlmlargefeat',\n",
       " 'reggae.00082.wavlmlargefeat',\n",
       " 'reggae.00083.wavlmlargefeat',\n",
       " 'reggae.00084.wavlmlargefeat',\n",
       " 'reggae.00085.wavlmlargefeat',\n",
       " 'reggae.00086.wavlmlargefeat',\n",
       " 'reggae.00087.wavlmlargefeat',\n",
       " 'reggae.00088.wavlmlargefeat',\n",
       " 'reggae.00089.wavlmlargefeat',\n",
       " 'reggae.00090.wavlmlargefeat',\n",
       " 'reggae.00091.wavlmlargefeat',\n",
       " 'reggae.00092.wavlmlargefeat',\n",
       " 'reggae.00093.wavlmlargefeat',\n",
       " 'reggae.00094.wavlmlargefeat',\n",
       " 'reggae.00095.wavlmlargefeat',\n",
       " 'reggae.00096.wavlmlargefeat',\n",
       " 'reggae.00097.wavlmlargefeat',\n",
       " 'reggae.00098.wavlmlargefeat',\n",
       " 'reggae.00099.wavlmlargefeat',\n",
       " 'rock.00000.wavlmlargefeat',\n",
       " 'rock.00001.wavlmlargefeat',\n",
       " 'rock.00002.wavlmlargefeat',\n",
       " 'rock.00003.wavlmlargefeat',\n",
       " 'rock.00004.wavlmlargefeat',\n",
       " 'rock.00005.wavlmlargefeat',\n",
       " 'rock.00006.wavlmlargefeat',\n",
       " 'rock.00007.wavlmlargefeat',\n",
       " 'rock.00008.wavlmlargefeat',\n",
       " 'rock.00009.wavlmlargefeat',\n",
       " 'rock.00010.wavlmlargefeat',\n",
       " 'rock.00011.wavlmlargefeat',\n",
       " 'rock.00012.wavlmlargefeat',\n",
       " 'rock.00013.wavlmlargefeat',\n",
       " 'rock.00014.wavlmlargefeat',\n",
       " 'rock.00015.wavlmlargefeat',\n",
       " 'rock.00016.wavlmlargefeat',\n",
       " 'rock.00017.wavlmlargefeat',\n",
       " 'rock.00018.wavlmlargefeat',\n",
       " 'rock.00019.wavlmlargefeat',\n",
       " 'rock.00020.wavlmlargefeat',\n",
       " 'rock.00021.wavlmlargefeat',\n",
       " 'rock.00022.wavlmlargefeat',\n",
       " 'rock.00023.wavlmlargefeat',\n",
       " 'rock.00024.wavlmlargefeat',\n",
       " 'rock.00025.wavlmlargefeat',\n",
       " 'rock.00026.wavlmlargefeat',\n",
       " 'rock.00027.wavlmlargefeat',\n",
       " 'rock.00028.wavlmlargefeat',\n",
       " 'rock.00029.wavlmlargefeat',\n",
       " 'rock.00030.wavlmlargefeat',\n",
       " 'rock.00031.wavlmlargefeat',\n",
       " 'rock.00032.wavlmlargefeat',\n",
       " 'rock.00033.wavlmlargefeat',\n",
       " 'rock.00034.wavlmlargefeat',\n",
       " 'rock.00035.wavlmlargefeat',\n",
       " 'rock.00036.wavlmlargefeat',\n",
       " 'rock.00037.wavlmlargefeat',\n",
       " 'rock.00038.wavlmlargefeat',\n",
       " 'rock.00039.wavlmlargefeat',\n",
       " 'rock.00040.wavlmlargefeat',\n",
       " 'rock.00041.wavlmlargefeat',\n",
       " 'rock.00042.wavlmlargefeat',\n",
       " 'rock.00043.wavlmlargefeat',\n",
       " 'rock.00044.wavlmlargefeat',\n",
       " 'rock.00045.wavlmlargefeat',\n",
       " 'rock.00046.wavlmlargefeat',\n",
       " 'rock.00047.wavlmlargefeat',\n",
       " 'rock.00048.wavlmlargefeat',\n",
       " 'rock.00049.wavlmlargefeat',\n",
       " 'rock.00050.wavlmlargefeat',\n",
       " 'rock.00051.wavlmlargefeat',\n",
       " 'rock.00052.wavlmlargefeat',\n",
       " 'rock.00053.wavlmlargefeat',\n",
       " 'rock.00054.wavlmlargefeat',\n",
       " 'rock.00055.wavlmlargefeat',\n",
       " 'rock.00056.wavlmlargefeat',\n",
       " 'rock.00057.wavlmlargefeat',\n",
       " 'rock.00058.wavlmlargefeat',\n",
       " 'rock.00059.wavlmlargefeat',\n",
       " 'rock.00060.wavlmlargefeat',\n",
       " 'rock.00061.wavlmlargefeat',\n",
       " 'rock.00062.wavlmlargefeat',\n",
       " 'rock.00063.wavlmlargefeat',\n",
       " 'rock.00064.wavlmlargefeat',\n",
       " 'rock.00065.wavlmlargefeat',\n",
       " 'rock.00066.wavlmlargefeat',\n",
       " 'rock.00067.wavlmlargefeat',\n",
       " 'rock.00068.wavlmlargefeat',\n",
       " 'rock.00069.wavlmlargefeat',\n",
       " 'rock.00070.wavlmlargefeat',\n",
       " 'rock.00071.wavlmlargefeat',\n",
       " 'rock.00072.wavlmlargefeat',\n",
       " 'rock.00073.wavlmlargefeat',\n",
       " 'rock.00074.wavlmlargefeat',\n",
       " 'rock.00075.wavlmlargefeat',\n",
       " 'rock.00076.wavlmlargefeat',\n",
       " 'rock.00077.wavlmlargefeat',\n",
       " 'rock.00078.wavlmlargefeat',\n",
       " 'rock.00079.wavlmlargefeat',\n",
       " 'rock.00080.wavlmlargefeat',\n",
       " 'rock.00081.wavlmlargefeat',\n",
       " 'rock.00082.wavlmlargefeat',\n",
       " 'rock.00083.wavlmlargefeat',\n",
       " 'rock.00084.wavlmlargefeat',\n",
       " 'rock.00085.wavlmlargefeat',\n",
       " 'rock.00086.wavlmlargefeat',\n",
       " 'rock.00087.wavlmlargefeat',\n",
       " 'rock.00088.wavlmlargefeat',\n",
       " 'rock.00089.wavlmlargefeat',\n",
       " 'rock.00090.wavlmlargefeat',\n",
       " 'rock.00091.wavlmlargefeat',\n",
       " 'rock.00092.wavlmlargefeat',\n",
       " 'rock.00093.wavlmlargefeat',\n",
       " 'rock.00094.wavlmlargefeat',\n",
       " 'rock.00095.wavlmlargefeat',\n",
       " 'rock.00096.wavlmlargefeat',\n",
       " 'rock.00097.wavlmlargefeat',\n",
       " 'rock.00098.wavlmlargefeat',\n",
       " 'rock.00099.wavlmlargefeat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to feature files\n",
    "path_features = 'features'\n",
    "extension     = 'wavlmlargefeat'\n",
    "\n",
    "all_files = [file for file in os.listdir(path_features) if file.endswith(extension)]\n",
    "\n",
    "sorted_all_files = sorted(all_files)\n",
    "sorted_all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763734c-8b7b-49e9-a724-b6b05bdf0f33",
   "metadata": {},
   "source": [
    "### Create a stratified 3-fold holdout with shuffled 334, 333, and 333 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367495bb-7ff5-41e6-966c-27b85f2e8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 334 ['blues.00017.wavlmlargefeat', 'disco.00035.wavlmlargefeat', 'reggae.00053.wavlmlargefeat', 'metal.00048.wavlmlargefeat', 'hiphop.00042.wavlmlargefeat'] ['blues', 'disco', 'reggae', 'metal', 'hiphop']\n",
      "Fold 2: 333 ['reggae.00089.wavlmlargefeat', 'jazz.00068.wavlmlargefeat', 'metal.00080.wavlmlargefeat', 'rock.00084.wavlmlargefeat', 'metal.00040.wavlmlargefeat'] ['reggae', 'jazz', 'metal', 'rock', 'metal']\n",
      "Fold 3: 333 ['blues.00011.wavlmlargefeat', 'jazz.00039.wavlmlargefeat', 'pop.00039.wavlmlargefeat', 'country.00044.wavlmlargefeat', 'hiphop.00022.wavlmlargefeat'] ['blues', 'jazz', 'pop', 'country', 'hiphop']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume you have a list of filenames from the GTzan dataset\n",
    "# Replace 'filenames' with your actual list of filenames\n",
    "filenames = sorted_all_files\n",
    "\n",
    "# Shuffle the filenames\n",
    "random.shuffle(filenames)\n",
    "\n",
    "# Extract genre labels from filenames\n",
    "genres = [filename.split('.')[0] for filename in filenames]\n",
    "\n",
    "# Split the filenames and genre labels into train and test sets\n",
    "# We'll create 3 folds with approximately 340, 330, and 330 samples each\n",
    "# Stratify based on genres to ensure each fold has proportional representation of genres\n",
    "fold1_gtzan, remaining_filenames, fold1_genres, remaining_genres = train_test_split(\n",
    "    filenames, genres, train_size=334, stratify=genres, random_state=42\n",
    ")\n",
    "\n",
    "# Remaining filenames and genres after fold 1\n",
    "# Since we have 1000 - 340 = 660 remaining samples, we split them into two folds of 330 each\n",
    "fold2_gtzan, fold3_gtzan, fold2_genres, fold3_genres = train_test_split(\n",
    "    remaining_filenames, remaining_genres, train_size=333, stratify=remaining_genres, random_state=42\n",
    ")\n",
    "\n",
    "# Now fold1_filenames, fold2_filenames, fold3_filenames contain the filenames for each fold\n",
    "# Similarly, fold1_genres, fold2_genres, fold3_genres contain the corresponding genres\n",
    "\n",
    "# Example usage:\n",
    "print(\"Fold 1:\", len(fold1_gtzan), fold1_gtzan[:5], fold1_genres[:5])\n",
    "print(\"Fold 2:\", len(fold2_gtzan),fold2_gtzan[:5], fold2_genres[:5])\n",
    "print(\"Fold 3:\", len(fold3_gtzan),fold3_gtzan[:5], fold3_genres[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e4b92-b653-4950-af31-d82dc1a08e84",
   "metadata": {},
   "source": [
    "### All feature vectors into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5599ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTzan fold1\n",
    "dfs = []\n",
    "for file in fold1_gtzan:\n",
    "    df = pd.read_csv(os.path.join(path_features, file))\n",
    "    dfs.append(df)\n",
    "\n",
    "df_fold1_gtzan = pd.concat(dfs, ignore_index=True)\n",
    "# Drop first index column (unamed 0)\n",
    "df_fold1_gtzan.drop(df_fold1_gtzan.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "# GTzan fold2\n",
    "dfs = []\n",
    "for file in fold2_gtzan:\n",
    "    df = pd.read_csv(os.path.join(path_features, file))\n",
    "    dfs.append(df)\n",
    "\n",
    "df_fold2_gtzan = pd.concat(dfs, ignore_index=True)\n",
    "# Drop first index column (unamed 0)\n",
    "df_fold2_gtzan.drop(df_fold2_gtzan.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "# GTzan fold3\n",
    "dfs = []\n",
    "for file in fold3_gtzan:\n",
    "    df = pd.read_csv(os.path.join(path_features, file))\n",
    "    dfs.append(df)\n",
    "\n",
    "df_fold3_gtzan = pd.concat(dfs, ignore_index=True)\n",
    "# Drop first index column (unamed 0)\n",
    "df_fold3_gtzan.drop(df_fold3_gtzan.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb633802-a0e5-4570-9d5f-630a4d4e3376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501107, 1024), (499672, 1024), (499656, 1024))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fold1_gtzan.shape, df_fold2_gtzan.shape, df_fold3_gtzan.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a43bb",
   "metadata": {},
   "source": [
    "### Process label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0cb636-0c94-4735-a26a-60561c57116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   genre  track_number  label\n",
      "0  blues            17      0\n",
      "1  blues            17      0\n",
      "2  blues            17      0\n",
      "3  blues            17      0\n",
      "4  blues            17      0\n",
      "    genre  track_number  label\n",
      "0  reggae            89      8\n",
      "1  reggae            89      8\n",
      "2  reggae            89      8\n",
      "3  reggae            89      8\n",
      "4  reggae            89      8\n",
      "   genre  track_number  label\n",
      "0  blues            11      0\n",
      "1  blues            11      0\n",
      "2  blues            11      0\n",
      "3  blues            11      0\n",
      "4  blues            11      0\n"
     ]
    }
   ],
   "source": [
    "# Path to the GTzan dataset\n",
    "gtzan_path_features = \"features\"\n",
    "\n",
    "# Dictionary to map genre names to numeric labels\n",
    "genre_label_map = {\n",
    "    \"blues\": 0,\n",
    "    \"classical\": 1,\n",
    "    \"country\": 2,\n",
    "    \"disco\": 3,\n",
    "    \"hiphop\": 4,\n",
    "    \"jazz\": 5,\n",
    "    \"metal\": 6,\n",
    "    \"pop\": 7,\n",
    "    \"reggae\": 8,\n",
    "    \"rock\": 9\n",
    "}\n",
    "\n",
    "#####################################################################################################\n",
    "# GTzan Fold1\n",
    "# Initialize an empty list to store data\n",
    "data_list = []\n",
    "# Iterate through the files\n",
    "for filename in fold1_gtzan:\n",
    "    genre_path = os.path.join(gtzan_path_features, filename)\n",
    "    # print(genre_path)\n",
    "    # Extract genre, track number, and extension from filename\n",
    "    genre_track, extension = os.path.splitext(filename)\n",
    "    # Split the genre_track into genre and track number\n",
    "    genre, track_number = genre_track.split('.')\n",
    "    # Count number of lines in the corresponding feature file\n",
    "    feature_filename = f\"{genre}.{track_number}.wavlmlargefeat\"\n",
    "    # feature_filepath = os.path.join(genre_path, feature_filename)\n",
    "    feature_filepath = os.path.join(gtzan_path_features, feature_filename)\n",
    "    if os.path.exists(feature_filepath):\n",
    "        with open(feature_filepath, 'r') as f:\n",
    "            num_lines = sum(1 for line in f)\n",
    "            num_lines = num_lines - 1\n",
    "        # Append a dictionary to the list replicated by the number of lines\n",
    "        for _ in range(num_lines):\n",
    "            data_list.append({\n",
    "                \"genre\": genre,\n",
    "                \"track_number\": int(track_number),\n",
    "                \"label\": genre_label_map[genre]\n",
    "            })\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_fold1_lab = pd.DataFrame(data_list)\n",
    "# Print first few rows of the DataFrame\n",
    "print(df_fold1_lab.head())\n",
    "\n",
    "#####################################################################################################\n",
    "# GTzan Fold2\n",
    "# Initialize an empty list to store data\n",
    "data_list = []\n",
    "# Iterate through the files\n",
    "for filename in fold2_gtzan:\n",
    "    genre_path = os.path.join(gtzan_path_features, filename)\n",
    "    # print(genre_path)\n",
    "    # Extract genre, track number, and extension from filename\n",
    "    genre_track, extension = os.path.splitext(filename)\n",
    "    # Split the genre_track into genre and track number\n",
    "    genre, track_number = genre_track.split('.')\n",
    "    # Count number of lines in the corresponding feature file\n",
    "    feature_filename = f\"{genre}.{track_number}.wavlmlargefeat\"\n",
    "    # feature_filepath = os.path.join(genre_path, feature_filename)\n",
    "    feature_filepath = os.path.join(gtzan_path_features, feature_filename)\n",
    "    if os.path.exists(feature_filepath):\n",
    "        with open(feature_filepath, 'r') as f:\n",
    "            num_lines = sum(1 for line in f)\n",
    "            num_lines = num_lines - 1\n",
    "        # Append a dictionary to the list replicated by the number of lines\n",
    "        for _ in range(num_lines):\n",
    "            data_list.append({\n",
    "                \"genre\": genre,\n",
    "                \"track_number\": int(track_number),\n",
    "                \"label\": genre_label_map[genre]\n",
    "            })\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_fold2_lab = pd.DataFrame(data_list)\n",
    "# Print first few rows of the DataFrame\n",
    "print(df_fold2_lab.head())\n",
    "\n",
    "#####################################################################################################\n",
    "# GTzan Fold3\n",
    "# Initialize an empty list to store data\n",
    "data_list = []\n",
    "# Iterate through the files\n",
    "for filename in fold3_gtzan:\n",
    "    genre_path = os.path.join(gtzan_path_features, filename)\n",
    "    # print(genre_path)\n",
    "    # Extract genre, track number, and extension from filename\n",
    "    genre_track, extension = os.path.splitext(filename)\n",
    "    # Split the genre_track into genre and track number\n",
    "    genre, track_number = genre_track.split('.')\n",
    "    # Count number of lines in the corresponding feature file\n",
    "    feature_filename = f\"{genre}.{track_number}.wavlmlargefeat\"\n",
    "    # feature_filepath = os.path.join(genre_path, feature_filename)\n",
    "    feature_filepath = os.path.join(gtzan_path_features, feature_filename)\n",
    "    if os.path.exists(feature_filepath):\n",
    "        with open(feature_filepath, 'r') as f:\n",
    "            num_lines = sum(1 for line in f)\n",
    "            num_lines = num_lines - 1\n",
    "        # Append a dictionary to the list replicated by the number of lines\n",
    "        for _ in range(num_lines):\n",
    "            data_list.append({\n",
    "                \"genre\": genre,\n",
    "                \"track_number\": int(track_number),\n",
    "                \"label\": genre_label_map[genre]\n",
    "            })\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_fold3_lab = pd.DataFrame(data_list)\n",
    "# Print first few rows of the DataFrame\n",
    "print(df_fold3_lab.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572759e",
   "metadata": {},
   "source": [
    "## Train a GRU classification model for 10 music genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a681dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a081309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b3bb1-b470-4847-8f42-06f2c678bf3b",
   "metadata": {},
   "source": [
    "### Which fold is which?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "810c4566-158f-4273-b4db-88183ab240c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feat = df_fold3_gtzan\n",
    "df_train_lab  = df_fold3_lab\n",
    "\n",
    "df_valid_feat = df_fold2_gtzan\n",
    "df_valid_lab  = df_fold2_lab\n",
    "\n",
    "df_test_feat = df_fold1_gtzan\n",
    "df_test_lab  = df_fold1_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2814445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 1.8020\n",
      "Epoch [1/1000], Validation Loss: 1.8243\n",
      "Saved model with best validation loss to best_model_gtzan.pth\n",
      "Epoch [2/1000], Loss: 1.6932\n",
      "Epoch [3/1000], Loss: 1.6796\n",
      "Epoch [3/1000], Validation Loss: 1.7738\n",
      "Saved model with best validation loss to best_model_gtzan.pth\n",
      "Epoch [4/1000], Loss: 1.6337\n",
      "Epoch [5/1000], Loss: 1.6226\n",
      "Epoch [5/1000], Validation Loss: 1.7677\n",
      "Saved model with best validation loss to best_model_gtzan.pth\n",
      "Epoch [6/1000], Loss: 1.6364\n",
      "Epoch [7/1000], Loss: 1.6938\n",
      "Epoch [7/1000], Validation Loss: 1.7678\n",
      "Epoch [8/1000], Loss: 1.6395\n",
      "Epoch [9/1000], Loss: 1.6622\n",
      "Epoch [9/1000], Validation Loss: 1.7670\n",
      "Saved model with best validation loss to best_model_gtzan.pth\n",
      "Epoch [10/1000], Loss: 1.6319\n",
      "Epoch [11/1000], Loss: 1.5883\n",
      "Epoch [11/1000], Validation Loss: 1.7690\n",
      "Epoch [12/1000], Loss: 1.6620\n",
      "Epoch [13/1000], Loss: 1.6283\n",
      "Epoch [13/1000], Validation Loss: 1.7660\n",
      "Saved model with best validation loss to best_model_gtzan.pth\n",
      "Epoch [14/1000], Loss: 1.6379\n",
      "Epoch [15/1000], Loss: 1.6559\n",
      "Epoch [15/1000], Validation Loss: 1.7670\n",
      "Epoch [16/1000], Loss: 1.6005\n",
      "Epoch [17/1000], Loss: 1.6475\n",
      "Epoch [17/1000], Validation Loss: 1.7684\n",
      "Epoch [18/1000], Loss: 1.6022\n",
      "Epoch [19/1000], Loss: 1.6061\n",
      "Epoch [19/1000], Validation Loss: 1.7651\n",
      "Saved model with best validation loss to best_model_gtzan.pth\n",
      "Epoch [20/1000], Loss: 1.5949\n",
      "Epoch [21/1000], Loss: 1.6276\n",
      "Epoch [21/1000], Validation Loss: 1.7641\n",
      "Saved model with best validation loss to best_model_gtzan.pth\n",
      "Epoch [22/1000], Loss: 1.5946\n",
      "Epoch [23/1000], Loss: 1.6078\n",
      "Epoch [23/1000], Validation Loss: 1.7645\n",
      "Epoch [24/1000], Loss: 1.5806\n",
      "Epoch [25/1000], Loss: 1.6058\n",
      "Epoch [25/1000], Validation Loss: 1.7676\n",
      "Epoch [26/1000], Loss: 1.6192\n",
      "Epoch [27/1000], Loss: 1.6101\n",
      "Epoch [27/1000], Validation Loss: 1.7696\n",
      "Epoch [28/1000], Loss: 1.5683\n",
      "Epoch [29/1000], Loss: 1.6000\n",
      "Epoch [29/1000], Validation Loss: 1.7693\n",
      "Epoch [30/1000], Loss: 1.5705\n",
      "Epoch [31/1000], Loss: 1.5952\n",
      "Epoch [31/1000], Validation Loss: 1.7716\n",
      "Epoch [32/1000], Loss: 1.5830\n",
      "Epoch [33/1000], Loss: 1.6143\n",
      "Epoch [33/1000], Validation Loss: 1.7668\n",
      "Epoch [34/1000], Loss: 1.5976\n",
      "Epoch [35/1000], Loss: 1.6130\n",
      "Epoch [35/1000], Validation Loss: 1.7704\n",
      "Epoch [36/1000], Loss: 1.5610\n",
      "Epoch [37/1000], Loss: 1.5871\n",
      "Epoch [37/1000], Validation Loss: 1.7688\n",
      "Epoch [38/1000], Loss: 1.6182\n",
      "Epoch [39/1000], Loss: 1.5852\n",
      "Epoch [39/1000], Validation Loss: 1.7696\n",
      "Epoch [40/1000], Loss: 1.6072\n",
      "Epoch [41/1000], Loss: 1.5382\n",
      "Epoch [41/1000], Validation Loss: 1.7729\n",
      "Epoch [42/1000], Loss: 1.6012\n",
      "Epoch [43/1000], Loss: 1.5574\n",
      "Epoch [43/1000], Validation Loss: 1.7717\n",
      "Epoch [44/1000], Loss: 1.5593\n",
      "Epoch [45/1000], Loss: 1.5309\n",
      "Epoch [45/1000], Validation Loss: 1.7683\n",
      "Epoch [46/1000], Loss: 1.5388\n",
      "Epoch [47/1000], Loss: 1.5793\n",
      "Epoch [47/1000], Validation Loss: 1.7703\n",
      "Epoch [48/1000], Loss: 1.6064\n",
      "Epoch [49/1000], Loss: 1.5748\n",
      "Epoch [49/1000], Validation Loss: 1.7701\n",
      "Epoch [50/1000], Loss: 1.5523\n",
      "Epoch [51/1000], Loss: 1.5348\n",
      "Epoch [51/1000], Validation Loss: 1.7731\n",
      "Epoch [52/1000], Loss: 1.5613\n",
      "Epoch [53/1000], Loss: 1.5798\n",
      "Epoch [53/1000], Validation Loss: 1.7732\n",
      "Epoch [54/1000], Loss: 1.6127\n",
      "Epoch [55/1000], Loss: 1.6027\n",
      "Epoch [55/1000], Validation Loss: 1.7721\n",
      "Epoch [56/1000], Loss: 1.5831\n",
      "Epoch [57/1000], Loss: 1.5945\n",
      "Epoch [57/1000], Validation Loss: 1.7707\n",
      "Epoch [58/1000], Loss: 1.5717\n",
      "Epoch [59/1000], Loss: 1.6289\n",
      "Epoch [59/1000], Validation Loss: 1.7702\n",
      "Epoch [60/1000], Loss: 1.6073\n",
      "Epoch [61/1000], Loss: 1.5738\n",
      "Epoch [61/1000], Validation Loss: 1.7698\n",
      "Epoch [62/1000], Loss: 1.6420\n",
      "Epoch [63/1000], Loss: 1.5950\n",
      "Epoch [63/1000], Validation Loss: 1.7724\n",
      "Epoch [64/1000], Loss: 1.5415\n",
      "Epoch [65/1000], Loss: 1.5354\n",
      "Epoch [65/1000], Validation Loss: 1.7704\n",
      "Epoch [66/1000], Loss: 1.5656\n",
      "Epoch [67/1000], Loss: 1.5677\n",
      "Epoch [67/1000], Validation Loss: 1.7688\n",
      "Epoch [68/1000], Loss: 1.5775\n",
      "Epoch [69/1000], Loss: 1.5719\n",
      "Epoch [69/1000], Validation Loss: 1.7713\n",
      "Epoch [70/1000], Loss: 1.5562\n",
      "Epoch [71/1000], Loss: 1.5949\n",
      "Epoch [71/1000], Validation Loss: 1.7708\n",
      "Epoch [72/1000], Loss: 1.6031\n",
      "Epoch [73/1000], Loss: 1.5422\n",
      "Epoch [73/1000], Validation Loss: 1.7717\n",
      "Epoch [74/1000], Loss: 1.5158\n",
      "Epoch [75/1000], Loss: 1.5026\n",
      "Epoch [75/1000], Validation Loss: 1.7703\n",
      "Epoch [76/1000], Loss: 1.5868\n",
      "Epoch [77/1000], Loss: 1.5628\n",
      "Epoch [77/1000], Validation Loss: 1.7708\n",
      "Epoch [78/1000], Loss: 1.5560\n",
      "Epoch [79/1000], Loss: 1.5484\n",
      "Epoch [79/1000], Validation Loss: 1.7716\n",
      "Epoch [80/1000], Loss: 1.5760\n",
      "Epoch [81/1000], Loss: 1.5841\n",
      "Epoch [81/1000], Validation Loss: 1.7709\n",
      "Early stopping at epoch 81 as validation loss has not improved for 30 consecutive validations.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.optim.lr_scheduler import (\n",
    "    StepLR, ReduceLROnPlateau, MultiStepLR, ExponentialLR, CosineAnnealingLR\n",
    ")\n",
    "\n",
    "#####################################\n",
    "# Training fold\n",
    "features = df_train_feat.values.astype(np.float32)\n",
    "labels   = df_train_lab['label'].values.astype(np.float32)\n",
    "\n",
    "# Normalize the features between -1 and 1 (adjust scaling based on your data)\n",
    "# [-1 1]\n",
    "# features = (features - np.min(features)) / (np.max(features) - np.min(features)) * 2 - 1\n",
    "# [0 1]\n",
    "# features = (features - np.min(features)) / (np.max(features) - np.min(features))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "features_tensor = torch.from_numpy(features)\n",
    "labels_tensor   = torch.from_numpy(labels)\n",
    "######\n",
    "sequence_length = 1\n",
    "num_features    = features.shape[1]\n",
    "num_samples     = features.shape[0]\n",
    "\n",
    "# Calculate the number of sequences that can be formed\n",
    "num_sequences = num_samples // sequence_length\n",
    "\n",
    "# Truncate the tensor to fit the full sequences\n",
    "features_tensor = features_tensor[:num_sequences * sequence_length, :]\n",
    "labels_tensor = labels_tensor[:num_sequences * sequence_length]\n",
    "\n",
    "# Reshape the tensor\n",
    "features_tensor = features_tensor.view(num_sequences, sequence_length, num_features)\n",
    "######################################\n",
    "\n",
    "#####################################\n",
    "# Validation fold\n",
    "features2 = df_valid_feat.values.astype(np.float32)\n",
    "labels2   = df_valid_lab['label'].values.astype(np.float32)\n",
    "\n",
    "# Normalize the features between -1 and 1 (adjust scaling based on your data)\n",
    "# features = (features - np.min(features)) / (np.max(features) - np.min(features)) * 2 - 1\n",
    "# features2 = (features2 - np.min(features)) / (np.max(features) - np.min(features))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "features_tensor2 = torch.from_numpy(features2)\n",
    "labels_tensor2   = torch.from_numpy(labels2)\n",
    "######\n",
    "sequence_length2 = 1\n",
    "num_features2    = features2.shape[1]\n",
    "num_samples2     = features2.shape[0]\n",
    "\n",
    "# Calculate the number of sequences that can be formed\n",
    "num_sequences2 = num_samples2 // sequence_length2\n",
    "\n",
    "# Truncate the tensor to fit the full sequences\n",
    "features_tensor2 = features_tensor2[:num_sequences2 * sequence_length2, :]\n",
    "labels_tensor2 = labels_tensor2[:num_sequences2 * sequence_length2]\n",
    "\n",
    "# Reshape the tensor\n",
    "features_tensor2 = features_tensor2.view(num_sequences2, sequence_length2, num_features2)\n",
    "######################################\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train = features_tensor\n",
    "X_test  = features_tensor2\n",
    "y_train = labels_tensor\n",
    "y_test  = labels_tensor2\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size   = num_features\n",
    "hidden_size  = 64 #128, 64, 32, 16\n",
    "hidden_size1  = 128 #128 \n",
    "hidden_size2  = 64 #64 \n",
    "num_layers   = 2 # 4\n",
    "num_classes  = 10 # GTzan\n",
    "dropout_prob = 0.40\n",
    "l2_reg       = 0.001 \n",
    "# =======================\n",
    "# Define the Convolutional GRU model\n",
    "class ConvGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(ConvGRUModel, self).__init__()\n",
    "        # GRU layer\n",
    "        self.convgru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout_prob, batch_first=True)\n",
    "        # Batch normalization layer\n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_size)  # Assuming batch normalization is applied along the hidden dimension        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagate GRU\n",
    "        gru_out, _ = self.convgru(x)\n",
    "        # Transpose to swap time and hidden dimensions\n",
    "        gru_out = gru_out.transpose(1, 2)\n",
    "        # Apply batch normalization\n",
    "        gru_out = self.batchnorm(gru_out)\n",
    "        # Transpose back\n",
    "        gru_out = gru_out.transpose(1, 2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        output = self.fc(gru_out[:, -1, :])  # Take the output from the last time step\n",
    "        # Apply softmax activation\n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "#model = ConvGRUModel(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "#==============================\n",
    "# Simple MLP model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleMLP_OneHidden(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_prob, l2_reg):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        # Batch normalization layer for input\n",
    "        self.input_batchnorm = nn.BatchNorm1d(hidden_size)\n",
    "        # Hidden layer\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        # Batch normalization layer for hidden layer\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(hidden_size)\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        # L2 regularization parameter\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Remove the extra dimension\n",
    "        x = x.squeeze(1)\n",
    "        # Check input shape\n",
    "        #print('Input shape:', x.size())\n",
    "        # Forward pass through input layer\n",
    "        x = self.input_layer(x)\n",
    "        # Apply batch normalization to the output of the input layer\n",
    "        x = self.input_batchnorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through hidden layer\n",
    "        x = self.hidden_layer(x)\n",
    "        # Apply batch normalization to the output of the hidden layer\n",
    "        x = self.hidden_batchnorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through output layer\n",
    "        x = self.output_layer(x)\n",
    "        # Apply softmax activation\n",
    "        output = F.softmax(x, dim=1)\n",
    "        \n",
    "        return output\n",
    "# Example usage:\n",
    "#input_size = 10  # Example input size\n",
    "#hidden_size = 64  # Number of units in the hidden layer\n",
    "#output_size = 2  # Example output size\n",
    "#dropout_prob = 0.5  # Dropout probability\n",
    "#model = SimpleMLP(input_size, hidden_size, num_classes, dropout_prob, l2_reg)\n",
    "#==============================\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes, dropout_prob, l2_reg):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size1)\n",
    "        # Batch normalization layer for input\n",
    "        self.input_batchnorm = nn.BatchNorm1d(hidden_size1)\n",
    "        # First hidden layer\n",
    "        self.hidden_layer1 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        # Batch normalization layer for first hidden layer\n",
    "        self.hidden_batchnorm1 = nn.BatchNorm1d(hidden_size2)\n",
    "        # Second hidden layer\n",
    "        self.hidden_layer2 = nn.Linear(hidden_size2, hidden_size2)\n",
    "        # Batch normalization layer for second hidden layer\n",
    "        self.hidden_batchnorm2 = nn.BatchNorm1d(hidden_size2)\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size2, num_classes)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        # L2 regularization parameter\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Remove the extra dimension\n",
    "        x = x.squeeze(1)\n",
    "        # Forward pass through input layer\n",
    "        x = self.input_layer(x)\n",
    "        # Apply batch normalization to the output of the input layer\n",
    "        x = self.input_batchnorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through first hidden layer\n",
    "        x = self.hidden_layer1(x)\n",
    "        # Apply batch normalization to the output of the first hidden layer\n",
    "        x = self.hidden_batchnorm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through second hidden layer\n",
    "        x = self.hidden_layer2(x)\n",
    "        # Apply batch normalization to the output of the second hidden layer\n",
    "        x = self.hidden_batchnorm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through output layer\n",
    "        x = self.output_layer(x)\n",
    "        # Apply softmax activation\n",
    "        output = F.softmax(x, dim=1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "model = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes, dropout_prob, l2_reg)\n",
    "#==============================\n",
    "\n",
    "\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Define your loss function (criterion)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsgrad=False)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=ls_reg)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "#scheduler = StepLR(optimizer, step_size=10, gamma=0.01)  # Reduce lr by 10% every 10 epochs\n",
    "\n",
    "# Train the model\n",
    "num_epochs     = 1000\n",
    "batch_size     = 1500\n",
    "validate_every = 2  # Validate every 2 epochs\n",
    "patience       = 30  # Stop training if validation loss doesn't improve for 5 consecutive validations\n",
    "\n",
    "##################\n",
    "##################\n",
    "train_dataset = TensorDataset(X_train, y_train.to(torch.int64))\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "##################\n",
    "##################\n",
    "\n",
    "# Initialize a list to store the training loss values\n",
    "train_loss_values = []\n",
    "validation_loss_values = []\n",
    "\n",
    "best_validation_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "best_model_path = 'best_model_gtzan.pth'  # Define the path to save the best model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X.to(device))\n",
    "        loss = criterion(outputs, batch_y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update learning rate after each epoch (StepLR example)\n",
    "        # scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    average_epoch_loss = epoch_loss / len(train_loader)\n",
    "    train_loss_values.append(average_epoch_loss)\n",
    "    \n",
    "    # Validate the model every validate_every epochs using the test partition\n",
    "    if epoch % validate_every == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test.to(device))\n",
    "            validation_loss = criterion(test_outputs, y_test.to(torch.int64).to(device))  # Adjust target size\n",
    "\n",
    "        validation_loss_values.append(validation_loss.item())\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {validation_loss.item():.4f}')\n",
    "        \n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            early_stop_counter = 0\n",
    "            \n",
    "            # Save the model with the best validation loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f'Saved model with best validation loss to {best_model_path}')\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1} as validation loss has not improved for {patience} consecutive validations.')\n",
    "            break\n",
    "            \n",
    "        model.train()  # Set the model back to training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851ef95-fba3-4cad-a672-477a95fe5e93",
   "metadata": {},
   "source": [
    "### Plot Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeadeff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the training loss values\n",
    "plt.plot(train_loss_values, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b78f817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss values\n",
    "epochs = range(1, len(train_loss_values) + 1)\n",
    "plt.plot(epochs, train_loss_values, label='Training Loss')\n",
    "plt.plot(range(0, len(validation_loss_values) * validate_every, validate_every), validation_loss_values, label='Validation Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991cc41b-687f-4ade-8a69-8f5c527fe61c",
   "metadata": {},
   "source": [
    "### Test the best model on train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf4ef987-2990-4193-b733-8eb710fcdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(predictions):\n",
    "  \"\"\"\n",
    "  Converts a 10-dimensional probability vector to the class label (index of max probability).\n",
    "  Args:\n",
    "      predictions: A torch.Tensor of size (batch_size, 10) containing probability predictions.\n",
    "  Returns:\n",
    "      A torch.Tensor of size (batch_size) containing the predicted class labels (integers).\n",
    "  \"\"\"\n",
    "  # Get the index of the maximum probability along the dimension with 10 elements (classes)\n",
    "  _, predicted_labels = torch.max(predictions, dim=1)\n",
    "  return predicted_labels\n",
    "    \n",
    "# Example usage\n",
    "# predict_y_int = predict_label(predict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e15112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5318\n",
      "Accuracy on Training set = 0.9290531885937525\n",
      "Validation Loss: 1.7641\n",
      "Accuracy on Validation set = 0.6956883715717511\n"
     ]
    }
   ],
   "source": [
    "import audmetric\n",
    "\n",
    "# Test the model\n",
    "# Load the best model for testing\n",
    "#best_model = ConvGRUModel(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "#best_model = SimpleMLP(input_size, hidden_size, num_classes, dropout_prob, l2_reg)\n",
    "best_model = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes, dropout_prob, l2_reg)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# Training set\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(X_train.to(device))\n",
    "    test_loss    = criterion(test_outputs, y_train.to(torch.int64).to(device))\n",
    "print(f'Train Loss: {test_loss.item():.4f}')\n",
    "print(\"Accuracy on Training set = \" + str(audmetric.accuracy(df_train_lab['label'], predict_label(test_outputs.cpu()))))\n",
    "\n",
    "# Validation set\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(X_test.to(device))\n",
    "    test_loss    = criterion(test_outputs, y_test.to(torch.int64).to(device))\n",
    "print(f'Validation Loss: {test_loss.item():.4f}')\n",
    "print(\"Accuracy on Validation set = \" + str(audmetric.accuracy(df_valid_lab['label'], predict_label(test_outputs.cpu()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3317ec0-f413-4a17-8c1a-ced5e816ee05",
   "metadata": {},
   "source": [
    "### Load Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c604ab31-b494-4504-89fc-6b202e1eb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features3 = df_test_feat.values.astype(np.float32)\n",
    "labels3   = df_test_lab['label'].values.astype(np.float32)\n",
    "\n",
    "# Normalize the features between -1 and 1 (adjust scaling based on your data)\n",
    "# features = (features - np.min(features)) / (np.max(features) - np.min(features)) * 2 - 1\n",
    "\n",
    "# features3 = (features3 - np.min(features)) / (np.max(features) - np.min(features))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "features_tensor3 = torch.from_numpy(features3)\n",
    "labels_tensor3   = torch.from_numpy(labels3)\n",
    "\n",
    "# Assuming you want a sequence length of 1\n",
    "# features_tensor = features_tensor.unsqueeze(1)\n",
    "\n",
    "######\n",
    "# Reshape features tensor with sequence length of 50\n",
    "sequence_length3 = 1\n",
    "num_features3    = features3.shape[1]\n",
    "num_samples3     = features3.shape[0]\n",
    "\n",
    "# Calculate the number of sequences that can be formed\n",
    "num_sequences3 = num_samples3 // sequence_length3\n",
    "\n",
    "# Truncate the tensor to fit the full sequences\n",
    "features_tensor3 = features_tensor3[:num_sequences3 * sequence_length3, :]\n",
    "labels_tensor3   = labels_tensor3[:num_sequences3 * sequence_length3]\n",
    "\n",
    "# Reshape the tensor\n",
    "features_tensor3 = features_tensor3.view(num_sequences3, sequence_length3, num_features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84528c98-3fe5-405b-9dce-fb0ebc557366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7715\n",
      "Accuracy on Test set = 0.6878510976697592\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# Load the best model for testing\n",
    "#best_model = ConvGRUModel(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "#best_model = SimpleMLP(input_size, hidden_size, num_classes, dropout_prob, l2_reg)\n",
    "best_model = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes, dropout_prob, l2_reg)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# Test set\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(features_tensor3.to(device))\n",
    "    test_loss    = criterion(test_outputs, labels_tensor3.to(torch.int64).to(device))\n",
    "print(f'Test Loss: {test_loss.item():.4f}')\n",
    "print(\"Accuracy on Test set = \" + str(audmetric.accuracy(df_test_lab['label'], predict_label(test_outputs.cpu()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f7ba5-2fad-4ee4-8fc6-1851002fe524",
   "metadata": {},
   "source": [
    "### Aggregation of Predictions for each track (wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60cead37-cd6b-4871-8e93-06dc81e714fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test set = 76.34730538922156 %\n"
     ]
    }
   ],
   "source": [
    "df_test_lab['pred'] = predict_label(test_outputs.cpu())\n",
    "\n",
    "df_test_probs = pd.DataFrame(test_outputs.cpu())\n",
    "\n",
    "cols = df_test_lab.columns.to_list() + df_test_probs.columns.to_list()\n",
    "dft = [df_test_lab, df_test_probs]\n",
    "df_test_pred = np.concatenate(dft, axis=1)\n",
    "df_test_pred = pd.DataFrame(df_test_pred, columns=cols)\n",
    "\n",
    "# df_test_lab.shape, df_test_probs.shape, df_test_pred.shape\n",
    "\n",
    "# Group by 'genre' and 'track_number', then calculate the average of each column 0 to 9\n",
    "average_values = df_test_pred.groupby(['genre', 'track_number', 'label'])[list(range(10))].mean().reset_index()\n",
    "\n",
    "average_values['max_value_column'] = average_values.iloc[:, 3:].idxmax(axis=1)\n",
    "\n",
    "print(\"Accuracy on Test set = \" + str(100*audmetric.accuracy(average_values['label'], average_values['max_value_column'])) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9894f8a5-c8c7-4d51-aaf1-0427672ddd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7715\n",
      "Accuracy on Test set = 0.6878510976697592\n",
      "Accuracy on Test set = 76.34730538922156 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss: {test_loss.item():.4f}')\n",
    "print(\"Accuracy on Test set = \" + str(audmetric.accuracy(df_test_lab['label'], predict_label(test_outputs.cpu()))))\n",
    "print(\"Accuracy on Test set = \" + str(100*audmetric.accuracy(average_values['label'], average_values['max_value_column'])) + \" %\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03b44301-544e-4549-be98-52e1bef93510",
   "metadata": {},
   "source": [
    "75.37537537537537 %"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88d2bd4d-cb20-4da3-a20a-26760882035f",
   "metadata": {},
   "source": [
    "WavLMbasefeat\n",
    "\n",
    "Model:\n",
    "Convolutional GRU model\n",
    "class ConvGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(ConvGRUModel, self).__init__()     \n",
    "        # GRU layer\n",
    "        self.convgru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout_prob, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        # Forward propagate GRU\n",
    "        gru_out, _ = self.convgru(x)\n",
    "        # Decode the hidden state of the last time step\n",
    "        output = self.fc(gru_out[:, -1, :])  # Take the output from the last time step\n",
    "        # Apply softmax activation\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output\n",
    "model = ConvGRUModel(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "\n",
    "Parameters:\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size   = num_features\n",
    "hidden_size  = 64\n",
    "num_layers   = 4\n",
    "#output_size  = 1  # Single output for regression between -1 and +1\n",
    "num_classes  = 10 # GTzan\n",
    "dropout_prob = 0.20 \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.01)  # Reduce lr by 10% every 10 epochs\n",
    "\n",
    "# Train the model\n",
    "num_epochs     = 1000\n",
    "batch_size     = 1500\n",
    "validate_every = 2  # Validate every 2 epochs\n",
    "patience       = 20  # Stop training if validation loss doesn't improve for 5 consecutive validations\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train.to(torch.int64))\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "Results:\n",
    "Fold 1-2-3 Segments\n",
    "Train Loss: 1.5140\n",
    "Accuracy on Training set = 0.9469061342444757\n",
    "Validation Loss: 1.8023\n",
    "Accuracy on Validation set = 0.657724877361455\n",
    "Test Loss: 1.8088\n",
    "Accuracy on Test set = 0.6512586545003402\n",
    "\n",
    "Fold 2-3-1 Segments\n",
    "Train Loss: 1.4765\n",
    "Accuracy on Training set = 0.9844227532278305\n",
    "Validation Loss: 1.8020\n",
    "Accuracy on Validation set = 0.658192259975187\n",
    "Test Loss: 1.7928\n",
    "Accuracy on Test set = 0.6674862689998723\n",
    "\n",
    "Fold 3-1-2 Segments\n",
    "Train Loss: 1.5108\n",
    "Accuracy on Training set = 0.9502041061351904\n",
    "Validation Loss: 1.7902\n",
    "Accuracy on Validation set = 0.6699490675692936\n",
    "Test Loss: 1.7947\n",
    "Accuracy on Test set = 0.6652363006090397\n",
    "\n",
    "Fold 1-3-2 Segments\n",
    "Train Loss: 1.5708\n",
    "Accuracy on Training set = 0.8897668124920168\n",
    "Validation Loss: 1.8206\n",
    "Accuracy on Validation set = 0.6393184455917077\n",
    "Test Loss: 1.8194\n",
    "Accuracy on Test set = 0.6403323199349931\n",
    "\n",
    "Fold 2-1-3 Segments\n",
    "Train Loss: 1.4784\n",
    "Accuracy on Training set = 0.9825834252330182\n",
    "Validation Loss: 1.7868\n",
    "Accuracy on Validation set = 0.6732221548090433\n",
    "Test Loss: 1.8016\n",
    "Accuracy on Test set = 0.6585304358266298\n",
    "\n",
    "Fold 3-2-1 Segments\n",
    "Train Loss: 1.5109\n",
    "Accuracy on Training set = 0.9499479729459319\n",
    "Validation Loss: 1.7909\n",
    "Accuracy on Validation set = 0.6691451227786461\n",
    "Test Loss: 1.7957\n",
    "Accuracy on Test set = 0.664494587431345"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba970221-772a-40fa-b70d-c04e72aea225",
   "metadata": {},
   "source": [
    "WavLMbase4layerfeat\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes, dropout_prob, l2_reg):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size1)\n",
    "        # Batch normalization layer for input\n",
    "        self.input_batchnorm = nn.BatchNorm1d(hidden_size1)\n",
    "        # First hidden layer\n",
    "        self.hidden_layer1 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        # Batch normalization layer for first hidden layer\n",
    "        self.hidden_batchnorm1 = nn.BatchNorm1d(hidden_size2)\n",
    "        # Second hidden layer\n",
    "        self.hidden_layer2 = nn.Linear(hidden_size2, hidden_size2)\n",
    "        # Batch normalization layer for second hidden layer\n",
    "        self.hidden_batchnorm2 = nn.BatchNorm1d(hidden_size2)\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size2, num_classes)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        # L2 regularization parameter\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Remove the extra dimension\n",
    "        x = x.squeeze(1)\n",
    "        # Forward pass through input layer\n",
    "        x = self.input_layer(x)\n",
    "        # Apply batch normalization to the output of the input layer\n",
    "        x = self.input_batchnorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through first hidden layer\n",
    "        x = self.hidden_layer1(x)\n",
    "        # Apply batch normalization to the output of the first hidden layer\n",
    "        x = self.hidden_batchnorm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through second hidden layer\n",
    "        x = self.hidden_layer2(x)\n",
    "        # Apply batch normalization to the output of the second hidden layer\n",
    "        x = self.hidden_batchnorm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Forward pass through output layer\n",
    "        x = self.output_layer(x)\n",
    "        # Apply softmax activation\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "model = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes, dropout_prob, l2_reg)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "\n",
    "# Train the model\n",
    "num_epochs     = 1000\n",
    "batch_size     = 1500\n",
    "validate_every = 2  # Validate every 2 epochs\n",
    "patience       = 30  # Stop training if validation loss doesn't improve for 5 consecutive validations\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size   = num_features\n",
    "hidden_size  = 64 #128, 64, 32, 16\n",
    "hidden_size1  = 128 #128 \n",
    "hidden_size2  = 64 #64 \n",
    "num_layers   = 2 # 4\n",
    "num_classes  = 10 # GTzan\n",
    "dropout_prob = 0.40\n",
    "l2_reg       = 0.001 \n",
    "\n",
    "Fold 1-2-3 Segments\n",
    "Train Loss: 1.4775\n",
    "Accuracy on Training set = 0.9835285994520176\n",
    "Validation Loss: 1.7382\n",
    "Accuracy on Validation set = 0.7217682132327775\n",
    "Test Loss: 1.7303\n",
    "Accuracy on Test set = 0.72964432730773\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 80.48048048048048 %\n",
    "\n",
    "Fold 2-3-1 Segments\n",
    "Train Loss: 1.4712\n",
    "Accuracy on Training set = 0.9897742898145202\n",
    "Validation Loss: 1.7296\n",
    "Accuracy on Validation set = 0.7301486288800703\n",
    "Test Loss: 1.7269\n",
    "Accuracy on Test set = 0.7331090317314927\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 81.1377245508982 %\n",
    "\n",
    "Fold 3-1-2 Segments\n",
    "Train Loss: 1.4860\n",
    "Accuracy on Training set = 0.9750891032837636\n",
    "Validation Loss: 1.7237\n",
    "Accuracy on Validation set = 0.7361622474860859\n",
    "Test Loss: 1.7392\n",
    "Accuracy on Test set = 0.7204392111652186\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 75.97597597597597 %\n",
    "\n",
    "Fold 1-3-2 Segments\n",
    "Train Loss: 1.4785\n",
    "Accuracy on Training set = 0.9824904548729545\n",
    "Validation Loss: 1.7727\n",
    "Accuracy on Validation set = 0.6868780652765077\n",
    "Test Loss: 1.7414\n",
    "Accuracy on Test set = 0.7184049411279654\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 79.87987987987988 %\n",
    "\n",
    "Fold 2-1-3 Segments\n",
    "Train Loss: 1.4766\n",
    "Accuracy on Training set = 0.9843988607866017\n",
    "Validation Loss: 1.7353\n",
    "Accuracy on Validation set = 0.7245435004321004\n",
    "Test Loss: 1.7455\n",
    "Accuracy on Test set = 0.7145018219073098\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 78.37837837837837 %\n",
    "\n",
    "Fold 3-2-1 Segments\n",
    "Train Loss: 1.4672\n",
    "Accuracy on Training set = 0.9937508879421952\n",
    "Validation Loss: 1.7222\n",
    "Accuracy on Validation set = 0.7379569012274764\n",
    "Test Loss: 1.7475\n",
    "Accuracy on Test set = 0.7124646486016114\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 74.8502994011976 %\n",
    "\n",
    "WavLMbase8layerfeat\n",
    "\n",
    "Fold 1-2-3 Segments\n",
    "Train Loss: 1.5014\n",
    "Accuracy on Training set = 0.9595206588147004\n",
    "Validation Loss: 1.7860\n",
    "Accuracy on Validation set = 0.6735916268086214\n",
    "Test Loss: 1.7775\n",
    "Accuracy on Test set = 0.6823606630860235\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 79.27927927927928 %\n",
    "\n",
    "Fold 2-3-1 Segments\n",
    "Train Loss: 1.5242\n",
    "Accuracy on Training set = 0.9366227060777682\n",
    "Validation Loss: 1.7860\n",
    "Accuracy on Validation set = 0.673503774083294\n",
    "Test Loss: 1.7705\n",
    "Accuracy on Test set = 0.6891826889491658\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 80.23952095808383 %\n",
    "\n",
    "Fold 3-1-2 Segments\n",
    "Train Loss: 1.5046\n",
    "Accuracy on Training set = 0.9563799217167877\n",
    "Validation Loss: 1.7685\n",
    "Accuracy on Validation set = 0.691346270914792\n",
    "Test Loss: 1.8011\n",
    "Accuracy on Test set = 0.6585382937421201\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 74.77477477477478 %\n",
    "\n",
    "Fold 1-3-2 Segments\n",
    "Train Loss: 1.5167\n",
    "Accuracy on Training set = 0.9441260945150004\n",
    "Validation Loss: 1.7735\n",
    "Accuracy on Validation set = 0.6863408601548054\n",
    "Test Loss: 1.7956\n",
    "Accuracy on Test set = 0.6640196922091697\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 75.67567567567568 %\n",
    "\n",
    "Fold 2-1-3 Segments\n",
    "Train Loss: 1.5058\n",
    "Accuracy on Training set = 0.9551041645820408\n",
    "Validation Loss: 1.7640\n",
    "Accuracy on Validation set = 0.6958171413972668\n",
    "Test Loss: 1.7912\n",
    "Accuracy on Test set = 0.668348928608592\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 75.67567567567568 %\n",
    "\n",
    "Fold 3-2-1 Segments\n",
    "Train Loss: 1.5064\n",
    "Accuracy on Training set = 0.9543968270485308\n",
    "Validation Loss: 1.7987\n",
    "Accuracy on Validation set = 0.661051852148332\n",
    "Test Loss: 1.7738\n",
    "Accuracy on Test set = 0.6861788228437531\n",
    "Mean Aggregation\n",
    "Accuracy on Test set = 76.34730538922156 %"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1b5dae1-4cbd-4569-b826-d24b55458f17",
   "metadata": {},
   "source": [
    "WavLMlargefeat\n",
    "\n",
    "Fold 1-2-3 Segments\n",
    "Train Loss: 1.5115\n",
    "Accuracy on Training set = 0.9494088655206473\n",
    "Validation Loss: 1.7674\n",
    "Accuracy on Validation set = 0.6923086159110693\n",
    "Test Loss: 1.7609\n",
    "Accuracy on Test set = 0.6987278932671425\n",
    "Accuracy on Test set = 78.67867867867868 %\n",
    "\n",
    "Fold 2-3-1 Segments\n",
    "Train Loss: 1.4906\n",
    "Accuracy on Training set = 0.9703130784547191\n",
    "Validation Loss: 1.7547\n",
    "Accuracy on Validation set = 0.7049913424679471\n",
    "Test Loss: 1.7926\n",
    "Accuracy on Test set = 0.6671349183386377\n",
    "Accuracy on Test set = 79.04191616766467 %\n",
    "\n",
    "Fold 3-1-2 Segments\n",
    "Train Loss: 1.4868\n",
    "Accuracy on Training set = 0.9741314944001281\n",
    "Validation Loss: 1.7752\n",
    "Accuracy on Validation set = 0.6845826141612874\n",
    "Test Loss: 1.7502\n",
    "Accuracy on Test set = 0.7097845772090091\n",
    "Accuracy on Test set = 78.97897897897897 %\n",
    "\n",
    "Fold 1-3-2 Segments\n",
    "Train Loss: 1.4861\n",
    "Accuracy on Training set = 0.9749159441689697\n",
    "Validation Loss: 1.7539\n",
    "Accuracy on Validation set = 0.7061543542882308\n",
    "Test Loss: 1.7695\n",
    "Accuracy on Test set = 0.6904355482625096\n",
    "Accuracy on Test set = 76.27627627627628 %\n",
    "\n",
    "Fold 2-1-3 Segments\n",
    "Train Loss: 1.4754\n",
    "Accuracy on Training set = 0.985559769068369\n",
    "Validation Loss: 1.7902\n",
    "Accuracy on Validation set = 0.6697728247747703\n",
    "Test Loss: 1.7578\n",
    "Accuracy on Test set = 0.702126850359813\n",
    "Accuracy on Test set = 78.67867867867868 %\n",
    "\n",
    "Fold 3-2-1 Segments\n",
    "Train Loss: 1.5318\n",
    "Accuracy on Training set = 0.9290531885937525\n",
    "Validation Loss: 1.7641\n",
    "Accuracy on Validation set = 0.6956883715717511\n",
    "Test Loss: 1.7715\n",
    "Accuracy on Test set = 0.6878510976697592\n",
    "Accuracy on Test set = 76.34730538922156 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
